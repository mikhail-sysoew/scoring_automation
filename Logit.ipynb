{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pydotplus\n",
    "import time\n",
    "from IPython.display import Image  \n",
    "import pydot \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.040507555007935  sec\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df = pd.read_csv('C:\\\\users\\\\booba\\\\cc_sample.txt', sep=';',index_col=False, decimal=',') \n",
    "print(-start_time + time.time(),\" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Возращает оптимальное разбиение непрерывной переменной\n",
    "def split_numeric(x,y,max_bins):\n",
    "    x_train_t = np.array(x[x.notnull()]) #Учим только на непустых значениях    \n",
    "    y_train_t = np.array(y[x.notnull()])\n",
    "    x_train_t = x_train_t.reshape(x_train_t.shape[0], 1) #Это нужно для работы DecisionTreeClassifier\n",
    "    m_depth = int(np.log2(max_bins)) + 1 #Максимальная глубина дерева\n",
    "    bad_rate = y.mean()\n",
    "    start = 1\n",
    "    cv_scores = []\n",
    "    cv = 5\n",
    "    for i in range(start,m_depth): #Пробегаемся по всем длинам начиная с 1 до максимальной. На каждой итерации делаем кросс-валидацию\n",
    "        d_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=i, min_samples_leaf=0.025)\n",
    "        scores = cross_val_score(d_tree, x_train_t, y_train_t, cv=cv,scoring='roc_auc')   \n",
    "        cv_scores.append(scores.mean())\n",
    "    #    print(\"Number of bins = \", np.power(2,i),\"; GINI = \",2*scores.mean()-1)\n",
    "    best = np.argmax(cv_scores) + start #Выбираем по максимальному GINI на валидационной выборке\n",
    "    #print(\"Optimal number of bins: \", np.power(2,best), \"GINI = \",2*max(cv_scores)-1)\n",
    "    final_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=best, min_samples_leaf=0.025) #Строим финальное дерево\n",
    "    final_tree.fit(x_train_t, y_train_t)\n",
    "    #Финальное разбиение\n",
    "    opt_bins = final_tree.tree_.threshold[final_tree.tree_.feature >= 0]        \n",
    "    opt_bins = np.append(opt_bins,max(x_train_t)+1)#Добавляем верхнюю границу\n",
    "    opt_bins = np.append(opt_bins,min(x_train_t)-1)#Добавляем нижнюю границу\n",
    "    opt_bins = np.sort(opt_bins)    \n",
    "    return opt_bins #Возвращаем оптимальное разбиение\n",
    "\n",
    "#Выбирает оптимальное разбиение категориальной переменной\n",
    "def split_categorial(x,y):\n",
    "    #One-hot encoding\n",
    "    x_cat = pd.get_dummies(x,prefix = x.name)\n",
    "    bad_rate = y.mean()\n",
    "    max_bins = max(x.nunique(),20)\n",
    "    #Classification by decision tree\n",
    "    m_depth = max_bins+1\n",
    "    start = 1\n",
    "    cv_scores = []\n",
    "    cv = 5\n",
    "    for i in range(start,m_depth):\n",
    "        d_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=i, min_samples_leaf=0.025) \n",
    "        scores = cross_val_score(d_tree, x_cat, y, cv=cv,scoring='roc_auc') \n",
    "        cv_scores.append(scores.mean())\n",
    "    #    print(\"Number of bins = \", i,\"; GINI = \",2*scores.mean()-1)\n",
    "    best = np.argmax(cv_scores) + start #Выбираем по максимальному GINI на валидационной выборке\n",
    "    #print(\"Optimal number of bins: \",best, \"; GINI = \",2*max(cv_scores)-1)\n",
    "    final_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=best, min_samples_leaf=0.025) #Строим финальное дерево\n",
    "    final_tree.fit(x_cat, y)\n",
    "    \n",
    "    #Get leafes names\n",
    "    x_l = final_tree.apply(x_cat)\n",
    "    tmp = pd.DataFrame(x)\n",
    "    tmp[\"LEAF\"] = x_l\n",
    "    \n",
    "    #Make dictionary with optimal binning\n",
    "    d = {}\n",
    "    for leaf in tmp[\"LEAF\"].unique():\n",
    "        d[leaf]=str(x[tmp[\"LEAF\"]==leaf].unique())   \n",
    "    tmp[\"x_num\"] = tmp[\"LEAF\"].apply(lambda x: d.get(x))\n",
    "    return tmp[\"x_num\"]\n",
    "  \n",
    "#Пронумеровывает категории по возрастанию\n",
    "def make_dict(x):        \n",
    "        x_dict = x.groupby(0)[\"val\"].min().fillna(0).sort_values().reset_index().rename(index=str, columns={0: \"x\"})\n",
    "        x_dict['rownum'] = x_dict['val'].rank(method='first', na_option='top')\n",
    "        x_dict['rownum'] = x_dict['rownum'].apply(zero_pad)\n",
    "        x_dict['x_num'] = x_dict[\"rownum\"].map(str)+x_dict[\"x\"].map(str)\n",
    "        del x_dict['val']\n",
    "        del x_dict['rownum']\n",
    "        return x_dict    \n",
    "\n",
    "#Процедура биннинга. \n",
    "#Возвращает разбиненную выборку в двух режимах: one-hot или в normal \n",
    "#В этих режимах входные данные: \n",
    "#      x - выборка в любом формате\n",
    "#      y - таргеты\n",
    "#      max_bins - максимальное число групп\n",
    "#      optimal_bins - для mode = 'normal' или 'one-hot' задает предрассчитанные оптимальные бины\n",
    "#                     для mode='binning' считает оптимальные бины\n",
    "#Р\n",
    "def binning(x,y,max_bins,mode,optimal_bins):\n",
    "    variable_type = check_type(x)\n",
    "    if variable_type=='numeric':         \n",
    "        #Вспомогательная переменная, хранящая разбиения по непустым значениям\n",
    "        x_bin_t = pd.cut(x[x.notnull()],bins=optimal_bins)    \n",
    "        #Вспомогательная переменная, хранящая one-hot по непустым значениям\n",
    "        x_bin = pd.get_dummies(x_bin_t,prefix=x.name,drop_first=True)\n",
    "        #Добавляем колонку с пустыми значениями\n",
    "        x_bin[x.name+'_ISNULL']=0\n",
    "        x_null = pd.DataFrame(x[x.isnull()])\n",
    "        for i in x_bin.columns:\n",
    "            x_null[i]=0\n",
    "        x_null[x.name+'_ISNULL']=1\n",
    "        del x_null[x.name]\n",
    "        #Если нет NULL то колонку с dummy is null удаляем   \n",
    "        if len(x[x.isnull()])==0:\n",
    "            del x_null[x.name+'_ISNULL']\n",
    "            del x_bin[x.name+'_ISNULL']\n",
    "        #Вспомогательная переменная, которая хранит узкий и широкий вид, включая пустые значения    \n",
    "        x_pivot = pd.concat([x_bin_t,pd.DataFrame(x[x.isnull()])]).sort_index(axis=0)        \n",
    "        del x_pivot[x.name]\n",
    "        #Заполняем пустые значения MISSING\n",
    "        x_pivot = x_pivot.fillna('MISSING')\n",
    "        x_pivot['val'] = x        \n",
    "        #Добавляем категориям индекс (создается справочник)\n",
    "        x_d = make_dict(x_pivot)\n",
    "        x_pivot[\"rownum\"] = x_pivot.index.values\n",
    "        x_pivot = pd.merge(x_pivot,x_d,left_on=0,right_on=\"x\").sort_values(by='rownum').reset_index()[[\"x_num\"]]\n",
    "        #Джойним значения со справочником, удаляем исходные        \n",
    "        if mode=='one-hot': return pd.concat([x_bin,x_null]).sort_index(axis=0) #Возвращаем в виде on-hot                            \n",
    "        if mode=='normal': return x_pivot #Возвращаем в \"длинном и узком\" виде               \n",
    "    if variable_type=='cat': \n",
    "        x_bin = split_categorial(x,y)          \n",
    "        if mode=='one-hot': return pd.get_dummies(x_bin,prefix=x.name,drop_first=True)\n",
    "        if mode=='normal': return pd.DataFrame(x_bin)\n",
    "    if (mode=='binning')&(variable_type=='numeric'):\n",
    "        x_bins = split_numeric(x,y,max_bins)\n",
    "        return x_bins\n",
    "        \n",
    "#Добавляет лидирующие нули к категориям          \n",
    "def zero_pad(x):\n",
    "    if str(x)=='MISSING': return '000'\n",
    "    if len(str(x))==3: return str('00'+str(x))[:-2]+': '\n",
    "    if len(str(x))==4: return str('0'+str(x))[:-2]+': '\n",
    "    if len(str(x))==5: str(x)[:-2]+': '\n",
    "\n",
    "#Считает Information Value, Weight of evidence для заданного разбиения       \n",
    "def iv_table(x,y):\n",
    "    #На вход подается разбиненная с помощью процедуры binning переменная - x\n",
    "    #y - целевая переменная (флаги дефолта)\n",
    "    df_t = x\n",
    "    df_t[\"y\"] = y\n",
    "    df_t = df_t.rename(index=str, columns = {\"x_num\":\"x\"})\n",
    "    df_iv =pd.DataFrame({'count': df_t.groupby('x')['y'].count(), \n",
    "                     'bad_rate': df_t.groupby('x')['y'].mean(),\n",
    "                     'total_goods': df_t.groupby('x')['y'].count() - df_t.groupby('x')['y'].sum(),\n",
    "                     'total_bads': df_t.groupby('x')['y'].sum() \n",
    "                     }).reset_index()\n",
    "    df_iv[\"cumm_bads\"] = df_iv['total_bads'].cumsum()\n",
    "    df_iv[\"cumm_goods\"] = df_iv['total_goods'].cumsum()\n",
    "    df_iv[\"cumm_total\"] = df_iv['count'].cumsum()\n",
    "    df_iv[\"per_bad\"] = df_iv[\"total_bads\"]/df_iv[\"cumm_bads\"].max()\n",
    "    df_iv[\"per_good\"] = df_iv[\"total_goods\"]/df_iv[\"cumm_goods\"].max()\n",
    "    df_iv[\"woe\"] = np.log((df_iv[\"per_good\"])/(df_iv[\"per_bad\"]+0.000000001))\n",
    "    iv = (df_iv[\"per_good\"] - df_iv[\"per_bad\"])*np.log((df_iv[\"per_good\"])/(df_iv[\"per_bad\"]+0.000000001))\n",
    "    df_iv[\"iv\"] = iv.sum()       \n",
    "    return df_iv\n",
    "    \n",
    "#Выводит IV по переменной. На вход принимает данные в формате iv_table    \n",
    "def iv_value (df_iv):\n",
    "    return df_iv[\"iv\"].mean()\n",
    "\n",
    "#На вход подается массив, на выходе - признак: числовой или категориальный\n",
    "def check_type(x):\n",
    "    from pandas.api.types import is_string_dtype\n",
    "    from pandas.api.types import is_numeric_dtype   \n",
    "    #Удаляем пустые значения\n",
    "    x = x[x.notnull()]\n",
    "    #Если число различных значений меньше 4, то тип-категориальный\n",
    "    if x.nunique()<=4: return 'cat'\n",
    "    elif is_numeric_dtype(x): return 'numeric'\n",
    "    else: return 'cat'\n",
    "\n",
    "#Процедура отбора переменных по IV. На вход принимает список переменных, на выход выдает отчетные таблицы и оптимальное разбиение   \n",
    "def iv_selection(x,y,iv_threshold):\n",
    "    #print(\"Choosing variables with IV > \",iv_threshold)\n",
    "    var_list = []\n",
    "    #Структура для хранения оптимального разбиения\n",
    "    x_bins = {'name': [1,2,3]}\n",
    "    for i in x.columns:\n",
    "        x_bins[i] = binning(x[i],y,max_bins=8,mode='binning',optimal_bins=1)\n",
    "        x_bin = binning(x[i],y,max_bins=8,mode='normal',optimal_bins=x_bins[i])\n",
    "        x_iv = iv_table(x_bin,y)\n",
    "        iv = iv_value(x_iv)\n",
    "        if (iv<iv_threshold)|(iv>5): x_bins.pop(i)\n",
    "        print('________________________________________________________________________________________________________________')\n",
    "        print('                                                             ')\n",
    "        print(i,\"  IV = \", iv)\n",
    "        print(x_iv)\n",
    "    x_bins.pop('name')\n",
    "    return x_bins    \n",
    "\n",
    "#Процедура преобразования выборки в one-hot, учитывая биннинг. Нужно для подачи на вход процедуры расчета корреляций\n",
    "def dev_to_one_hot(x,y,list_optimal_bins):    \n",
    "    x_dev = pd.DataFrame(x.index.values)\n",
    "    for i in x.columns:\n",
    "        x_bin = binning(x[i],y,max_bins=8,mode='one-hot',optimal_bins = list_optimal_bins[i])\n",
    "        x_dev = pd.merge(x_dev,x_bin,left_index=True,right_index=True)\n",
    "    del x_dev[0]\n",
    "    return x_dev\n",
    "\n",
    "#Проверка, если количество различных категорий велико (Id-шники, даты, и т.д.) для того, чтобы выкинуть эти колонки\n",
    "def check_mass_cat(x):\n",
    "    drop_list=[]\n",
    "    for i in range(len(x.columns)):\n",
    "        x[x.columns[i]] = x[x.columns[i]].fillna(0)\n",
    "        #Если количество уникальных значений >= количеству строк / 2 и тип - категориальный\n",
    "        if x[x.columns[i]].nunique()>len(x)/2 and check_type(x[x.columns[i]])=='cat': drop_list.append(x.columns[i])\n",
    "        #Если на самую крупную группу приходится менее 1% выборки    \n",
    "        if max(x.groupby(x.columns[i])[x.columns[0]].count())/len(x)<0.01 and check_type(x[x.columns[i]])=='cat': drop_list.append(x.columns[i])\n",
    "    #Конец формирования списка переменных, которые надо выкинуть\n",
    "    #Формируем список переменных, которые надо оставить\n",
    "    var_list = x.columns.values\n",
    "    final_list=[]\n",
    "    for i in range(len(x.columns)):\n",
    "        x[x.columns[i]] = x[x.columns[i]].fillna(0)\n",
    "        #Если количество уникальных значений >= количеству строк / 2 и тип - категориальный\n",
    "        if x[x.columns[i]].nunique()>len(x)/3 and check_type(x[x.columns[i]])=='cat': drop_list.append(x.columns[i])\n",
    "        #Если на самую крупную группу приходится менее 1% выборки    \n",
    "        if max(x.groupby(x.columns[i])[x.columns[0]].count())/len(x)<0.01 and check_type(x[x.columns[i]])=='cat': drop_list.append(x.columns[i])\n",
    "    for elem in var_list:\n",
    "        if elem not in drop_list: final_list.append(elem)\n",
    "    return x[final_list]\n",
    "\n",
    "#Принимает на вход выборку в виде one-hot, на выходе дает ту же выборку с исключенными коррелирующими факторами\n",
    "def exclude_corr_factors(x_dev_t, corr_threshold,mode):\n",
    "    x_corr = x_dev_t.corr()\n",
    "    #Оставляем только колонки - потенциальные кандидаты на исключение (хотя бы одно значение корреляции выше трешхолда)\n",
    "    col_list=[]    \n",
    "    for i in range(len(x_corr.columns)):\n",
    "        #Заменяем диагональные значения на 0    \n",
    "        x_corr[x_corr.columns[i]][x_corr[x_corr.columns[i]].index.values[i]] = 0\n",
    "        #Если в колонке найдено, хотя бы одно значение с корреляцией больше трешхолда, добавляем ее в лист\n",
    "        if max(abs(x_corr[x_corr.columns[i]]))>corr_threshold: col_list.append(x_corr.columns[i])\n",
    "    #Оставляем только те колонки, из которых нужно выбрать которые выкинуть из-за корреляций            \n",
    "    x_dev_drop =  x_dev_t[col_list]\n",
    "    #Строим корреляционную матрицу из оставшихся\n",
    "    x_c = x_dev_drop.corr()\n",
    "    #Пустой список\n",
    "    corr_list = []\n",
    "    corr_list.append([])\n",
    "    exclude_iteration = 0\n",
    "    var_list = [0,1]\n",
    "    #Заполняем диагональ нулями\n",
    "    for i in range(len(x_c.columns)):        \n",
    "        x_c[x_c.columns[i]][x_c[x_c.columns[i]].index.values[i]] = 0\n",
    "    while len(var_list)>1&len(x_c)>0:\n",
    "        for i in range(len(x_c.columns)):        \n",
    "            x_c[x_c.columns[i]][x_c[x_c.columns[i]].index.values[i]] = 0\n",
    "        #Если нашли хотя бы одну колонку, которая коррелирует с первой, создаем пару в corr_list и записываем туда первую колонку\n",
    "        if max(abs(x_c[x_c.columns[0]]))>=corr_threshold:     \n",
    "            corr_list[exclude_iteration].append(x_c.columns[0])\n",
    "        #Пробегаемся по всем колонкам\n",
    "            for i in range(len(x_c.columns)):\n",
    "        #Записываем в пару к первой все коррелирующие с ней колонки\n",
    "                if abs(x_c[x_c.columns[0]].iloc[i])>=corr_threshold:\n",
    "                    corr_list[exclude_iteration].append(x_c.columns[i])\n",
    "            #Выкидываем все колонки, которые коррелируют с первой\n",
    "            var_list = [x for x in x_c.columns.values if x not in corr_list[exclude_iteration]]\n",
    "            x_dev_drop = x_dev_drop[var_list]\n",
    "            x_c = x_dev_drop.corr()\n",
    "            corr_list.append([])\n",
    "            exclude_iteration = exclude_iteration+1\n",
    "    #       print(\"Excluding correlations. Iteration = \",exclude_iteration,\"Corr list: \", corr_list)\n",
    "    #После обработки corr_list содержит все списки коррелирующих колонок. Из каждого списка оставляем только одну\n",
    "    cols_to_drop=[] #Список колонок, которые надо выкинуть\n",
    "    for i in range(len(corr_list)):\n",
    "        for j in range(len(corr_list[i])):\n",
    "            if j!=0: \n",
    "                cols_to_drop.append(corr_list[i][j])\n",
    "    #Оставляем в исходном списке только колонки не из col_to_drop\n",
    "    exclude_list = [x for x in x_dev_t.columns.values if x not in cols_to_drop]\n",
    "    x_dev_t = x_dev_t[exclude_list]\n",
    "    if mode=='var': return x_dev_t\n",
    "    if mode=='list': return exclude_list\n",
    "\n",
    "#Строит скоркарту\n",
    "def build_model(x,y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn import metrics\n",
    "    logit_model = LogisticRegression()\n",
    "    logit_model.fit(x,y)\n",
    "    return logit_model\n",
    "\n",
    "#Выводит готовую скоркарту\n",
    "def scorecard_view(col_list, model, odds_X_to_one,odds_score,double_odds):\n",
    "  #  print('Printing scorecard...')\n",
    "    cols = np.array('Intercept')\n",
    "    cols = np.append(cols,np.array(col_list))\n",
    "    vals = np.array(model.intercept_)\n",
    "    vals = np.append(vals,np.array(model.coef_))\n",
    "    scorecard = pd.DataFrame(cols)\n",
    "    scorecard.rename(columns={0: 'Variable'},inplace=True)\n",
    "    scorecard[\"Regression_coef\"] = pd.DataFrame(vals)\n",
    "    b = double_odds/np.log(2)\n",
    "    a = odds_score - b*np.log(odds_X_to_one)    \n",
    "    scorecard[\"Score\"] = scorecard[\"Regression_coef\"]*b\n",
    "    scorecard[\"Score\"][0] = scorecard[\"Score\"][0]+a\n",
    "    scorecard[\"Score\"] = round(scorecard[\"Score\"],2)\n",
    "    return scorecard\n",
    "\n",
    "def gini(model,x,y):\n",
    "    gini =  2*roc_auc_score(y,model.predict_proba(x)[:,1])-1\n",
    "   # print('GINI = ',2*roc_auc_score(y,model.predict_proba(x)[:,1])-1)   \n",
    "    return gini\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(share):\n",
    "    start_time = time.time()\n",
    "    #Формируем сэмпл для разработки\n",
    "    df_train, df_test = train_test_split(df,test_size=share)\n",
    "    df_train = df_train.reset_index()\n",
    "    df_test = df_test.reset_index()\n",
    "    x_sample_train = df_train.copy()\n",
    "    x_sample_test = df_test.copy()\n",
    "    x_sample_train = x_sample_train.drop(['CONTRACT_SRC_CODE','SCORE_FINAL','BAD_12_FLAG90','index'], axis=1)\n",
    "    x_sample_test = x_sample_test.drop(['CONTRACT_SRC_CODE','SCORE_FINAL','BAD_12_FLAG90','index'], axis=1)\n",
    "    #test_col_list = ['RATE_TR_ALL_L3_6M', 'SD_GENDER_CD']\n",
    "    #x_sample_train = x_sample_train[test_col_list]\n",
    "    #x_sample_test = x_sample_test[test_col_list]\n",
    "    #Целевая переменная\n",
    "    y_train = df_train[\"BAD_12_FLAG90\"][df_train['BAD_12_FLAG90'].notnull()] \n",
    "    y_test = df_test[\"BAD_12_FLAG90\"][df_test['BAD_12_FLAG90'].notnull()] \n",
    "    #Процедура отбора переменных по критерию порогового IV\n",
    "    var_list_bins = iv_selection(x_sample_train,y_train,0.02)\n",
    "    var_list = list(var_list_bins.keys())\n",
    "    x_sample_train = x_sample_train[var_list]\n",
    "    x_sample_test = x_sample_test[var_list]\n",
    "    #print('________________________________________________________________________________________________________________')\n",
    "    #Выводим графики WOE по переменным\n",
    "    #for col in x_sample.columns: print_woe_graph(iv_table(binning(x_sample[col],y,max_bins=10,mode='normal'),y),col)\n",
    "    #print('________________________________________________________________________________________________________________')\n",
    "    #Преобразуем в one-hot\n",
    "    x_dev_train = dev_to_one_hot(x_sample_train,y_train,list_optimal_bins = var_list_bins)\n",
    "    x_dev_test = dev_to_one_hot(x_sample_test,y_test,list_optimal_bins = var_list_bins)\n",
    "    #Исключаем коррелирующие переменные\n",
    "    x_dev_train = exclude_corr_factors(x_dev_train, 0.8, mode='var')\n",
    "    x_dev_train = x_dev_train[exclude_corr_factors(x_dev_train, 0.8, mode='list')]\n",
    "    x_dev_test = x_dev_test[exclude_corr_factors(x_dev_train, 0.8, mode='list')]\n",
    "    #print('________________________________________________________________________________________________________________')\n",
    "    #Строим логит регрессию\n",
    "    model_logit = build_model(x_dev_train,y_train)\n",
    "    #Выводим визуально получившуюся скоркарту\n",
    "    col_list = x_dev_train.columns\n",
    "    scorecard = scorecard_view(col_list,model_logit,odds_X_to_one=100,odds_score=700,double_odds=25)\n",
    "    #print(scorecard)\n",
    "    print('________________________________________________________________________________________________________________')\n",
    "    #Выводим GINI скоркарты\n",
    "    #print('Development sample: ')\n",
    "    gini_train = gini(model_logit,x_dev_train,y_train)\n",
    "    #print('Validation sample: ')\n",
    "    gini_test = gini(model_logit,x_dev_test,y_test)\n",
    "    #print(-start_time + time.time(),\" sec\")\n",
    "    start_time=0\n",
    "    return gini_train, gini_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________________________________________\n",
      "                                                             \n",
      "RATE_TR_ALL_L3_6M   IV =  0.33422839190719733\n",
      "                     x  bad_rate   count  total_bads  total_goods  cumm_bads  \\\n",
      "0    001: (-1.0, 0.21]  0.066656   12482         832        11650        832   \n",
      "1         002: MISSING  0.071447   77092        5508        71584       6340   \n",
      "2   003: (0.21, 0.335]  0.042485   17371         738        16633       7078   \n",
      "3  004: (0.335, 0.621]  0.020346  348320        7087       341233      14165   \n",
      "4  005: (0.621, 0.712]  0.032598   52611        1715        50896      15880   \n",
      "5  006: (0.712, 0.803]  0.049459   21614        1069        20545      16949   \n",
      "6  007: (0.803, 0.951]  0.058456   15225         890        14335      17839   \n",
      "7    008: (0.951, 2.0]  0.076827   23221        1784        21437      19623   \n",
      "\n",
      "   cumm_goods  cumm_total   per_bad  per_good       woe        iv  \n",
      "0       11650       12482  0.042399  0.021247 -0.690915  0.334228  \n",
      "1       83234       89574  0.280691  0.130553 -0.765474  0.334228  \n",
      "2       99867      106945  0.037609  0.030335 -0.214944  0.334228  \n",
      "3      441100      455265  0.361158  0.622332  0.544159  0.334228  \n",
      "4      491996      507876  0.087397  0.092823  0.060227  0.334228  \n",
      "5      512541      529490  0.054477  0.037469 -0.374250  0.334228  \n",
      "6      526876      544715  0.045355  0.026144 -0.550906  0.334228  \n",
      "7      548313      567936  0.090914  0.039096 -0.843884  0.334228  \n",
      "________________________________________________________________________________________________________________\n",
      "                                                             \n",
      "SD_GENDER_CD   IV =  0.046884786285427874\n",
      "       x  bad_rate   count  total_bads  total_goods  cumm_bads  cumm_goods  \\\n",
      "0  ['F']  0.027956  310349        8676       301673       8676      301673   \n",
      "1  ['M']  0.042498  257587       10947       246640      19623      548313   \n",
      "\n",
      "   cumm_total   per_bad  per_good       woe        iv  \n",
      "0      310349  0.442134  0.550184  0.218639  0.046885  \n",
      "1      567936  0.557866  0.449816 -0.215280  0.046885  \n",
      "________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    share=0.1\n",
    "    start_time = time.time()\n",
    "    #Формируем сэмпл для разработки\n",
    "    df_train, df_test = train_test_split(df,test_size=share)\n",
    "    df_train = df_train.reset_index()\n",
    "    df_test = df_test.reset_index()\n",
    "    x_sample_train = df_train.copy()\n",
    "    x_sample_test = df_test.copy()\n",
    "    x_sample_train = x_sample_train.drop(['CONTRACT_SRC_CODE','SCORE_FINAL','BAD_12_FLAG90','index'], axis=1)\n",
    "    x_sample_test = x_sample_test.drop(['CONTRACT_SRC_CODE','SCORE_FINAL','BAD_12_FLAG90','index'], axis=1)\n",
    "    test_col_list = ['RATE_TR_ALL_L3_6M', 'SD_GENDER_CD']\n",
    "    x_sample_train = x_sample_train[test_col_list]\n",
    "    x_sample_test = x_sample_test[test_col_list]\n",
    "    #Целевая переменная\n",
    "    y_train = df_train[\"BAD_12_FLAG90\"][df_train['BAD_12_FLAG90'].notnull()] \n",
    "    y_test = df_test[\"BAD_12_FLAG90\"][df_test['BAD_12_FLAG90'].notnull()] \n",
    "    #Процедура отбора переменных по критерию порогового IV\n",
    "    var_list_bins = iv_selection(x_sample_train,y_train,0.02)\n",
    "    var_list = list(var_list_bins.keys())\n",
    "    x_sample_train = x_sample_train[var_list]\n",
    "    x_sample_test = x_sample_test[var_list]\n",
    "    #print('________________________________________________________________________________________________________________')\n",
    "    #Выводим графики WOE по переменным\n",
    "    #for col in x_sample.columns: print_woe_graph(iv_table(binning(x_sample[col],y,max_bins=10,mode='normal'),y),col)\n",
    "    #print('________________________________________________________________________________________________________________')\n",
    "    #Преобразуем в one-hot\n",
    "    x_dev_train = dev_to_one_hot(x_sample_train,y_train,list_optimal_bins = var_list_bins)\n",
    "    x_dev_test = dev_to_one_hot(x_sample_test,y_test,list_optimal_bins = var_list_bins)\n",
    "    #Исключаем коррелирующие переменные\n",
    "    x_dev_train = exclude_corr_factors(x_dev_train, 0.8, mode='var')\n",
    "    x_dev_train = x_dev_train[exclude_corr_factors(x_dev_train, 0.8, mode='list')]\n",
    "    x_dev_test = x_dev_test[exclude_corr_factors(x_dev_train, 0.8, mode='list')]\n",
    "    #print('________________________________________________________________________________________________________________')\n",
    "    #Строим логит регрессию\n",
    "    model_logit = build_model(x_dev_train,y_train)\n",
    "    #Выводим визуально получившуюся скоркарту\n",
    "    col_list = x_dev_train.columns\n",
    "    scorecard = scorecard_view(col_list,model_logit,odds_X_to_one=100,odds_score=700,double_odds=25)\n",
    "    #print(scorecard)\n",
    "    print('________________________________________________________________________________________________________________')\n",
    "    #Выводим GINI скоркарты\n",
    "    #print('Development sample: ')\n",
    "    gini_train = gini(model_logit,x_dev_train,y_train)\n",
    "    #print('Validation sample: ')\n",
    "    gini_test = gini(model_logit,x_dev_test,y_test)\n",
    "    #print(-start_time + time.time(),\" sec\")\n",
    "    start_time=0\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grouper for '<class 'numpy.float64'>' not 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-af0041d33091>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"BAD_12_FLAG90\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'BAD_12_FLAG90'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#x_sample_train.columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmake_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_sample_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SCR_CLIENT_GROUP'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-68d7f1b0e356>\u001b[0m in \u001b[0;36mmake_dict\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m#Пронумеровывает категории по возрастанию\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mx_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"x\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0mx_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rownum'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'first'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_option\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'top'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mx_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rownum'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rownum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[0;32m   4269\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m   4270\u001b[0m                        \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4271\u001b[1;33m                        **kwargs)\n\u001b[0m\u001b[0;32m   4272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4273\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   1624\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m                                                     mutated=self.mutated)\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, mutated)\u001b[0m\n\u001b[0;32m   2636\u001b[0m                         \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2637\u001b[0m                         in_axis=in_axis) \\\n\u001b[1;32m-> 2638\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouping\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2640\u001b[0m         \u001b[0mgroupings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, index, grouper, obj, name, level, sort, in_axis)\u001b[0m\n\u001b[0;32m   2417\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2418\u001b[0m                     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2419\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Grouper for '%s' not 1-dimensional\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2420\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m                 if not (hasattr(self.grouper, \"__len__\") and\n",
      "\u001b[1;31mValueError\u001b[0m: Grouper for '<class 'numpy.float64'>' not 1-dimensional"
     ]
    }
   ],
   "source": [
    "    share=0.1\n",
    "    start_time = time.time()\n",
    "    #Формируем сэмпл для разработки\n",
    "    df_train, df_test = train_test_split(df,test_size=share)\n",
    "    df_train = df_train.reset_index()\n",
    "    df_test = df_test.reset_index()\n",
    "    x_sample_train = df_train.copy()\n",
    "    x_sample_test = df_test.copy()\n",
    "    x_sample_train = x_sample_train.drop(['CONTRACT_SRC_CODE','SCORE_FINAL','BAD_12_FLAG90','index'], axis=1)\n",
    "    x_sample_test = x_sample_test.drop(['CONTRACT_SRC_CODE','SCORE_FINAL','BAD_12_FLAG90','index'], axis=1)\n",
    "    #test_col_list = ['RATE_TR_ALL_L3_6M', 'SD_GENDER_CD']\n",
    "    #x_sample_train = x_sample_train[test_col_list]\n",
    "    #x_sample_test = x_sample_test[test_col_list]\n",
    "    y_train = df_train[\"BAD_12_FLAG90\"][df_train['BAD_12_FLAG90'].notnull()] \n",
    "    #x_sample_train.columns\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AVG_TERM_FACT', 'SCR_CLIENT_GROUP', 'CMPN_DM_AVAIL_NFLAG',\n",
       "       'CMPN_EMAIL_AVAIL_NFLAG', 'CMPN_TM_AVAIL_NFLAG', 'CNT_AGR_OPEN',\n",
       "       'CNT_AGR_WO_ARREAR_TO_CNT', 'CNT_OPENED_6M', 'CNT_OPENED_6M1Y',\n",
       "       'CNT_TR_CARD_TRANS_1M', 'CNT_TR_CASH_1M', 'CNT_TR_CASH_3M',\n",
       "       'CNT_TR_MEDICINE_6M', 'CNT_TR_PUBL_UTIL_1M', 'CNT_TR_PUBL_UTIL_3M',\n",
       "       'CNT_TR_PUBL_UTIL_6M', 'CNT_TR_RELAX_6M', 'CNT_TR_REPAIR_6M',\n",
       "       'CRD_CC_EVER_NFLAG', 'CRD_DC_MNTH_SNC_OPEN_QTY',\n",
       "       'CRD_DC_PAYROLL_PMT_NFLAG', 'CRD_DC_POS_HEALTHCARE_RUB_AMT',\n",
       "       'CRD_DC_POS_HEALTHCARE_RUB001', 'CRD_DC_POS_HOME_REPAIR_QTY',\n",
       "       'CRD_DC_SOCIAL_PMT_NFLAG', 'CRD_OTF_DC_CASH_QTY',\n",
       "       'CRD_OTF_DC_TOTAL_QTY', 'CRD_OTF_FEE_QTY', 'CRD_POS_AUTO_RUB_3M_AMT',\n",
       "       'CRD_POS_TOURISM_RUB_3M_AMT', 'CRD_TRX_DC_CASH_3M_QTY',\n",
       "       'CRD_TRX_DC_POS_RTRN_6M_QTY', 'DEP_TOPUP_12M_AVG_RUB_AMT',\n",
       "       'FIRST_OPENED', 'LAST_DEL_DAYS_PRC_MAX', 'LAST_OPENED',\n",
       "       'LBT_ACCT_DEP_CA_BAL_RUB_AMT', 'LBT_ACCT_DEP_MNTH_LST_CLS001',\n",
       "       'LBT_ACCT_DEP_MNTH_LST_CLSR_QTY', 'LBT_ACCT_DEP_TD_BAL_RUB_AMT',\n",
       "       'LBT_ACCT_DEP_TOT_BAL_RUB_AMT', 'LBT_ACCT_TOT_BAL_PREV_RUB_AMT',\n",
       "       'LBT_ACCT_TOT_BAL_PREV_RUB001', 'LBT_SOCIAL_L3M_AVG_RUB_AMT',\n",
       "       'MAX_ARREAR', 'MAX_TR_RECEIPT_3M_RUR', 'MIN_APP_DAYS',\n",
       "       'MIN_TERM_REQUEST_CLOSED_AGR', 'MONTHS_FRM_FIRST_AGR_OPEN001',\n",
       "       'RATE_TR_ALL_7D_3M', 'RATE_TR_ALL_7D_6M', 'RATE_TR_ALL_L1_3M',\n",
       "       'RATE_TR_ALL_L3_6M', 'RATE_TR_CARD_TRANS_L3_6M', 'RATE_TR_PAY_L1_6M',\n",
       "       'RATE_TR_PAY_L3_6M', 'SD_AGE_YRS_FRAC_NV', 'SD_GENDER_CD',\n",
       "       'SRV_AP_UTL_QTY', 'SRV_MB_TOT_QTY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = split_categorial(x_sample_train['SD_GENDER_CD'],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['A','B','C','D']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
