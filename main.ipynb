{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booba\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pydotplus\n",
    "from IPython.display import Image  \n",
    "import pydot \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\kaggle\\\\cc_sample.txt', sep=';',index_col=False, decimal=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Возращает оптимальное разбиение непрерывной переменной\n",
    "def split_numeric(x,y,max_bins):\n",
    "    x_train = x[x.notnull()] #Учим только на непустых значениях    \n",
    "    y_train = y[x.notnull()]\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1) #Это нужно для работы DecisionTreeClassifier\n",
    "    m_depth = int(np.log2(max_bins)) + 1 #Максимальная глубина дерева\n",
    "    bad_rate = y.mean()\n",
    "    start = 1\n",
    "    cv_scores = []\n",
    "    cv = 5\n",
    "    for i in range(start,m_depth): #Пробегаемся по всем длинам начиная с 1 до максимальной. На каждой итерации делаем кросс-валидацию\n",
    "        d_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=i, min_samples_leaf=0.025)\n",
    "        scores = cross_val_score(d_tree, x_train, y_train, cv=cv,scoring='roc_auc')   \n",
    "        cv_scores.append(scores.mean())\n",
    "    #    print(\"Number of bins = \", np.power(2,i),\"; GINI = \",2*scores.mean()-1)\n",
    "    best = np.argmax(cv_scores) + start #Выбираем по максимальному GINI на валидационной выборке\n",
    "    #print(\"Optimal number of bins: \", np.power(2,best), \"GINI = \",2*max(cv_scores)-1)\n",
    "    final_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=best, min_samples_leaf=0.025) #Строим финальное дерево\n",
    "    final_tree.fit(x_train, y_train)\n",
    "    #Финальное разбиение\n",
    "    opt_bins = final_tree.tree_.threshold[final_tree.tree_.feature >= 0]        \n",
    "    opt_bins = np.append(opt_bins,max(x_train)+1)#Добавляем верхнюю границу\n",
    "    opt_bins = np.append(opt_bins,min(x_train)-1)#Добавляем нижнюю границу\n",
    "    opt_bins = np.sort(opt_bins)    \n",
    "    return opt_bins #Возвращаем оптимальное разбиение\n",
    "\n",
    "#Выбирает оптимальное разбиение категориальной переменной\n",
    "def split_categorial(x,y):\n",
    "    #One-hot encoding\n",
    "    x_cat = pd.get_dummies(x,prefix = x.name)\n",
    "    bad_rate = y.mean()\n",
    "    max_bins = max(x.nunique(),20)\n",
    "    #Classification by decision tree\n",
    "    m_depth = max_bins+1\n",
    "    start = 1\n",
    "    cv_scores = []\n",
    "    cv = 5\n",
    "    for i in range(start,m_depth):\n",
    "        d_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=i, min_samples_leaf=0.025) \n",
    "        scores = cross_val_score(d_tree, x_cat, y, cv=cv,scoring='roc_auc') \n",
    "        cv_scores.append(scores.mean())\n",
    "    #    print(\"Number of bins = \", i,\"; GINI = \",2*scores.mean()-1)\n",
    "    best = np.argmax(cv_scores) + start #Выбираем по максимальному GINI на валидационной выборке\n",
    "    #print(\"Optimal number of bins: \",best, \"; GINI = \",2*max(cv_scores)-1)\n",
    "    final_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=best, min_samples_leaf=0.025) #Строим финальное дерево\n",
    "    final_tree.fit(x_cat, y)\n",
    "    \n",
    "    #Get leafes names\n",
    "    x_l = final_tree.apply(x_cat)\n",
    "    tmp = pd.DataFrame(x)\n",
    "    tmp[\"LEAF\"] = x_l\n",
    "    \n",
    "    #Make dictionary with optimal binning\n",
    "    d = {}\n",
    "    for leaf in tmp[\"LEAF\"].unique():\n",
    "        d[leaf]=str(x[tmp[\"LEAF\"]==leaf].unique())   \n",
    "    tmp[\"x_num\"] = tmp[\"LEAF\"].apply(lambda x: d.get(x))\n",
    "    return tmp[\"x_num\"]\n",
    "  \n",
    "#Пронумеровывает категории по возрастанию\n",
    "def make_dict(x):        \n",
    "        x_dict = x.groupby(0)[\"val\"].min().fillna(0).sort_values().reset_index().rename(index=str, columns={0: \"x\"})\n",
    "        x_dict['rownum'] = x_dict['val'].rank(method='first', na_option='top')\n",
    "        x_dict['rownum'] = x_dict['rownum'].apply(zero_pad)\n",
    "        x_dict['x_num'] = x_dict[\"rownum\"].map(str)+x_dict[\"x\"].map(str)\n",
    "        del x_dict['val']\n",
    "        del x_dict['rownum']\n",
    "        return x_dict    \n",
    "\n",
    "#Процедура биннинга. Возвращает разбиненную выборку в двух режимах: one-hot или в normal\n",
    "def binning(x,y,max_bins,mode):\n",
    "    variable_type = check_type(x)\n",
    "    if variable_type=='numeric': \n",
    "        #Вспомогательная переменная, хранящая разбиения по непустым значениям\n",
    "        x_bin_t = pd.cut(x[x.notnull()],bins=split_numeric(x,y,max_bins))    \n",
    "        #Вспомогательная переменная, хранящая one-hot по непустым значениям\n",
    "        x_bin = pd.get_dummies(x_bin_t,prefix=x.name,drop_first=True)\n",
    "        #Добавляем колонку с пустыми значениями\n",
    "        x_bin[x.name+'_ISNULL']=0\n",
    "        x_null = pd.DataFrame(x[x.isnull()])\n",
    "        for i in x_bin.columns:\n",
    "            x_null[i]=0\n",
    "        x_null[x.name+'_ISNULL']=1\n",
    "        del x_null[x.name]\n",
    "        #Если нет NULL то колонку с dummy is null удаляем   \n",
    "        if len(x[x.isnull()])==0:\n",
    "            del x_null[x.name+'_ISNULL']\n",
    "            del x_bin[x.name+'_ISNULL']\n",
    "        #Вспомогательная переменная, которая хранит узкий и широкий вид, включая пустые значения    \n",
    "        x_pivot = pd.concat([x_bin_t,pd.DataFrame(x[x.isnull()])]).sort_index(axis=0)        \n",
    "        del x_pivot[x.name]\n",
    "        #Заполняем пустые значения MISSING\n",
    "        x_pivot = x_pivot.fillna('MISSING')\n",
    "        x_pivot['val'] = x        \n",
    "        #Добавляем категориям индекс (создается справочник)\n",
    "        x_d = make_dict(x_pivot)\n",
    "        x_pivot[\"rownum\"] = x_pivot.index.values\n",
    "        x_pivot = pd.merge(x_pivot,x_d,left_on=0,right_on=\"x\").sort_values(by='rownum').reset_index()[[\"x_num\"]]\n",
    "        #Джойним значения со справочником, удаляем исходные        \n",
    "        if mode=='one-hot': return pd.concat([x_bin,x_null]).sort_index(axis=0) #Возвращаем в виде on-hot\n",
    "        if mode=='normal': return x_pivot #Возвращаем в \"длинном и узком\" виде\n",
    "    if variable_type=='cat': \n",
    "        x_bin = split_categorial(x,y)          \n",
    "        if mode=='one-hot': return pd.get_dummies(x_bin,prefix=x.name,drop_first=True)\n",
    "        if mode=='normal': return pd.DataFrame(x_bin)\n",
    "        \n",
    "#Добавляет лидирующие нули к категориям          \n",
    "def zero_pad(x):\n",
    "    if str(x)=='MISSING': return '000'\n",
    "    if len(str(x))==3: return str('00'+str(x))[:-2]+': '\n",
    "    if len(str(x))==4: return str('0'+str(x))[:-2]+': '\n",
    "    if len(str(x))==5: str(x)[:-2]+': '\n",
    "\n",
    "#Считает Information Value, Weight of evidence для заданного разбиения       \n",
    "def iv_table(x,y):\n",
    "    #На вход подается разбиненная с помощью процедуры binning переменная - x\n",
    "    #y - целевая переменная (флаги дефолта)\n",
    "    df_t = x\n",
    "    df_t[\"y\"] = y\n",
    "    df_t = df_t.rename(index=str, columns = {\"x_num\":\"x\"})\n",
    "    df_iv =pd.DataFrame({'count': df_t.groupby('x')['y'].count(), \n",
    "                     'bad_rate': df_t.groupby('x')['y'].mean(),\n",
    "                     'total_goods': df_t.groupby('x')['y'].count() - df_t.groupby('x')['y'].sum(),\n",
    "                     'total_bads': df_t.groupby('x')['y'].sum() \n",
    "                     }).reset_index()\n",
    "    df_iv[\"cumm_bads\"] = df_iv['total_bads'].cumsum()\n",
    "    df_iv[\"cumm_goods\"] = df_iv['total_goods'].cumsum()\n",
    "    df_iv[\"cumm_total\"] = df_iv['count'].cumsum()\n",
    "    df_iv[\"per_bad\"] = df_iv[\"total_bads\"]/df_iv[\"cumm_bads\"].max()\n",
    "    df_iv[\"per_good\"] = df_iv[\"total_goods\"]/df_iv[\"cumm_goods\"].max()\n",
    "    df_iv[\"woe\"] = np.log((df_iv[\"per_good\"])/(df_iv[\"per_bad\"]+0.000000001))\n",
    "    iv = (df_iv[\"per_good\"] - df_iv[\"per_bad\"])*np.log((df_iv[\"per_good\"])/(df_iv[\"per_bad\"]+0.000000001))\n",
    "    df_iv[\"iv\"] = iv.sum()       \n",
    "    return df_iv\n",
    "    \n",
    "#Выводит IV по переменной. На вход принимает данные в формате iv_table    \n",
    "def iv_value (df_iv):\n",
    "    return df_iv[\"iv\"].mean()\n",
    "\n",
    "#На вход подается массив, на выходе - признак: числовой или категориальный\n",
    "def check_type(x):\n",
    "    from pandas.api.types import is_string_dtype\n",
    "    from pandas.api.types import is_numeric_dtype   \n",
    "    #Удаляем пустые значения\n",
    "    x = x[x.notnull()]\n",
    "    #Если число различных значений меньше 4, то тип-категориальный\n",
    "    if x.nunique()<=4: return 'cat'\n",
    "    elif is_numeric_dtype(x): return 'numeric'\n",
    "    else: return 'cat'\n",
    "\n",
    "#Процедура отбора переменных по IV. На вход принимает список переменных, на выход выдает те, по которым IV больше заданного    \n",
    "def iv_selection(x,y,iv_threshold):\n",
    "    print(\"Choosing variables with IV > \",iv_threshold)\n",
    "    var_list = []\n",
    "    for i in range(len(x.columns)):\n",
    "        x_bin = binning(x[x.columns[i]],y,max_bins=32,mode='normal')\n",
    "        x_iv = iv_table(x_bin,y)\n",
    "        iv = iv_value(x_iv)\n",
    "        if (iv>=iv_threshold)&(iv<5): var_list.append(x.columns[i]) \n",
    "        print(x.columns[i],\"  IV = \", iv)\n",
    "    return var_list    \n",
    "\n",
    "#Процедура преобразования выборки в one-hot, учитывая биннинг. Нужно для подачи на вход процедуры расчета корреляций\n",
    "def dev_to_one_hot(x,y):    \n",
    "    x_dev = pd.DataFrame(x.index.values)\n",
    "    for i in range(len(x.columns)):\n",
    "        x_bin = binning(x[x.columns[i]],y,max_bins=8,mode='one-hot')\n",
    "        x_dev = pd.merge(x_dev,x_bin,left_index=True,right_index=True)\n",
    "    del x_dev[0]\n",
    "    return x_dev\n",
    "\n",
    "#Проверка, если количество различных категорий велико (Id-шники, даты, и т.д.) для того, чтобы выкинуть эти колонки\n",
    "def check_mass_cat(x):\n",
    "    drop_list=[]\n",
    "    for i in range(len(x.columns)):\n",
    "        x[x.columns[i]] = x[x.columns[i]].fillna(0)\n",
    "        #Если количество уникальных значений >= количеству строк / 2 и тип - категориальный\n",
    "        if x[x.columns[i]].nunique()>len(x)/2 and check_type(x[x.columns[i]])=='cat': drop_list.append(x.columns[i])\n",
    "        #Если на самую крупную группу приходится менее 1% выборки    \n",
    "        if max(x.groupby(x.columns[i])[x.columns[0]].count())/len(x)<0.01 and check_type(x[x.columns[i]])=='cat': drop_list.append(x.columns[i])\n",
    "    #Конец формирования списка переменных, которые надо выкинуть\n",
    "    #Формируем список переменных, которые надо оставить\n",
    "    var_list = x.columns.values\n",
    "    final_list=[]\n",
    "    for i in range(len(x.columns)):\n",
    "        x[x.columns[i]] = x[x.columns[i]].fillna(0)\n",
    "        #Если количество уникальных значений >= количеству строк / 2 и тип - категориальный\n",
    "        if x[x.columns[i]].nunique()>len(x)/3 and check_type(x[x.columns[i]])=='cat': drop_list.append(x.columns[i])\n",
    "        #Если на самую крупную группу приходится менее 1% выборки    \n",
    "        if max(x.groupby(x.columns[i])[x.columns[0]].count())/len(x)<0.01 and check_type(x[x.columns[i]])=='cat': drop_list.append(x.columns[i])\n",
    "    for elem in var_list:\n",
    "        if elem not in drop_list: final_list.append(elem)\n",
    "    return x[final_list]\n",
    "\n",
    "#Принимает на вход выборку в виде one-hot, на выходе дает ту же выборку с исключенными коррелирующими факторами\n",
    "def exclude_corr_factors(x_dev_t, corr_threshold):\n",
    "    x_corr = x_dev_t.corr()\n",
    "    #Оставляем только колонки - потенциальные кандидаты на исключение (хотя бы одно значение корреляции выше трешхолда)\n",
    "    col_list=[]    \n",
    "    for i in range(len(x_corr.columns)):\n",
    "        #Заменяем диагональные значения на 0    \n",
    "        x_corr[x_corr.columns[i]][x_corr[x_corr.columns[i]].index.values[i]] = 0\n",
    "        #Если в колонке найдено, хотя бы одно значение с корреляцией больше трешхолда, добавляем ее в лист\n",
    "        if max(abs(x_corr[x_corr.columns[i]]))>corr_threshold: col_list.append(x_corr.columns[i])\n",
    "    #Оставляем только те колонки, из которых нужно выбрать которые выкинуть из-за корреляций            \n",
    "    x_dev_drop =  x_dev_t[col_list]\n",
    "    #Строим корреляционную матрицу из оставшихся\n",
    "    x_c = x_dev_drop.corr()\n",
    "    #Пустой список\n",
    "    corr_list = []\n",
    "    corr_list.append([])\n",
    "    exclude_iteration = 0\n",
    "    var_list = [0,1]\n",
    "    #Заполняем диагональ нулями\n",
    "    for i in range(len(x_c.columns)):        \n",
    "        x_c[x_c.columns[i]][x_c[x_c.columns[i]].index.values[i]] = 0\n",
    "    while len(var_list)>1:\n",
    "        for i in range(len(x_c.columns)):        \n",
    "            x_c[x_c.columns[i]][x_c[x_c.columns[i]].index.values[i]] = 0\n",
    "        #Если нашли хотя бы одну колонку, которая коррелирует с первой, создаем пару в corr_list и записываем туда первую колонку\n",
    "        if max(abs(x_c[x_c.columns[0]]))>=corr_threshold:     \n",
    "            corr_list[exclude_iteration].append(x_c.columns[0])\n",
    "        #Пробегаемся по всем колонкам\n",
    "            for i in range(len(x_c.columns)):\n",
    "        #Записываем в пару к первой все коррелирующие с ней колонки\n",
    "                if abs(x_c[x_c.columns[0]].iloc[i])>=corr_threshold:\n",
    "                    corr_list[exclude_iteration].append(x_c.columns[i])\n",
    "            #Выкидываем все колонки, которые коррелируют с первой\n",
    "            var_list = [x for x in x_c.columns.values if x not in corr_list[exclude_iteration]]\n",
    "            x_dev_drop = x_dev_drop[var_list]\n",
    "            x_c = x_dev_drop.corr()\n",
    "            corr_list.append([])\n",
    "            exclude_iteration = exclude_iteration+1\n",
    "            print(\"Excluding correlations. Iteration = \",exclude_iteration,\"Corr list: \", corr_list)\n",
    "    #После обработки corr_list содержит все списки коррелирующих колонок. Из каждого списка оставляем только одну\n",
    "    cols_to_drop=[] #Список колонок, которые надо выкинуть\n",
    "    for i in range(len(corr_list)):\n",
    "        for j in range(len(corr_list[i])):\n",
    "            if j!=0: \n",
    "                cols_to_drop.append(corr_list[i][j])\n",
    "    #Оставляем в исходном списке только колонки не из col_to_drop\n",
    "    exclude_list = [x for x in x_dev_t.columns.values if x not in cols_to_drop]\n",
    "    x_dev_t = x_dev_t[exclude_list]\n",
    "    return x_dev_t\n",
    "\n",
    "#Строит скоркарту\n",
    "def build_model(x_dev,y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn import metrics\n",
    "    logit_model = LogisticRegression()\n",
    "    logit_model.fit(x_dev,y)\n",
    "    return logit_model\n",
    "\n",
    "#Выводит готовую скоркарту\n",
    "def scorecard_view(variables, model, odds_X_to_one,odds_score,double_odds):\n",
    "    print('Printing scorecard...')\n",
    "    cols = np.array('Intercept')\n",
    "    cols = np.append(cols,np.array(x_dev.columns))\n",
    "    vals = np.array(model_logit.intercept_)\n",
    "    vals = np.append(vals,np.array(model_logit.coef_))\n",
    "    scorecard = pd.DataFrame(cols)\n",
    "    scorecard.rename(columns={0: 'Variable'},inplace=True)\n",
    "    scorecard[\"Regression_coef\"] = pd.DataFrame(vals)\n",
    "    b = double_odds/np.log(2)\n",
    "    a = odds_score - b*np.log(odds_X_to_one)    \n",
    "    scorecard[\"Score\"] = scorecard[\"Regression_coef\"]*b\n",
    "    scorecard[\"Score\"][0] = scorecard[\"Score\"][0]+a\n",
    "    scorecard[\"Score\"] = round(scorecard[\"Score\"],2)\n",
    "    return scorecard\n",
    "\n",
    "def gini(model,x,y):\n",
    "    print('GINI = ',2*roc_auc_score(y,model.predict_proba(x)[:,1])-1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing variables with IV >  0.01\n",
      "AVG_TERM_FACT   IV =  0.07529116328716266\n",
      "SCR_CLIENT_GROUP   IV =  0.029623574915019227\n",
      "CMPN_DM_AVAIL_NFLAG   IV =  0.062417830515493045\n",
      "CMPN_EMAIL_AVAIL_NFLAG   IV =  0.06642798480058056\n",
      "CMPN_TM_AVAIL_NFLAG   IV =  0.11150475672704602\n",
      "CNT_AGR_OPEN   IV =  0.08078874279159776\n",
      "CNT_AGR_WO_ARREAR_TO_CNT   IV =  0.11140942897240287\n",
      "CNT_OPENED_6M   IV =  0.10254993926590619\n",
      "CNT_OPENED_6M1Y   IV =  0.07570383420215335\n",
      "CNT_TR_CARD_TRANS_1M   IV =  0.08181850450999963\n",
      "CNT_TR_CASH_1M   IV =  0.1657075302492795\n",
      "CNT_TR_CASH_3M   IV =  0.19085272825755517\n",
      "CNT_TR_MEDICINE_6M   IV =  0.1109921504640623\n",
      "CNT_TR_PUBL_UTIL_1M   IV =  0.06894588931980375\n",
      "CNT_TR_PUBL_UTIL_3M   IV =  0.09933518531059632\n",
      "CNT_TR_PUBL_UTIL_6M   IV =  0.11748936275724695\n",
      "CNT_TR_RELAX_6M   IV =  0.06578969351241108\n",
      "CNT_TR_REPAIR_6M   IV =  0.08173995793845994\n",
      "CRD_CC_EVER_NFLAG   IV =  0.13159466507796747\n",
      "CRD_DC_MNTH_SNC_OPEN_QTY   IV =  0.148915608764801\n",
      "CRD_DC_PAYROLL_PMT_NFLAG   IV =  0.11012667491497405\n",
      "CRD_DC_POS_HEALTHCARE_RUB_AMT   IV =  0.07780383874292192\n",
      "CRD_DC_POS_HEALTHCARE_RUB001   IV =  0.07780383874292192\n",
      "CRD_DC_POS_HOME_REPAIR_QTY   IV =  0.046409061622628554\n",
      "CRD_DC_SOCIAL_PMT_NFLAG   IV =  0.06081603739177586\n",
      "CRD_OTF_DC_CASH_QTY   IV =  0.14238311286861272\n",
      "CRD_OTF_DC_TOTAL_QTY   IV =  0.2613905753095071\n",
      "CRD_OTF_FEE_QTY   IV =  0.17795419438924454\n",
      "CRD_POS_AUTO_RUB_3M_AMT   IV =  0.04324909539472572\n",
      "CRD_POS_TOURISM_RUB_3M_AMT   IV =  0.014037373349096485\n",
      "CRD_TRX_DC_CASH_3M_QTY   IV =  0.2424447347337517\n",
      "CRD_TRX_DC_POS_RTRN_6M_QTY   IV =  0.02335500818048944\n",
      "DEP_TOPUP_12M_AVG_RUB_AMT   IV =  0.2450025956471124\n",
      "FIRST_OPENED   IV =  0.1426303812614136\n",
      "LAST_DEL_DAYS_PRC_MAX   IV =  0.0066814789980190435\n",
      "LAST_OPENED   IV =  0.11945921390284255\n",
      "LBT_ACCT_DEP_CA_BAL_RUB_AMT   IV =  0.15238518273226068\n",
      "LBT_ACCT_DEP_MNTH_LST_CLS001   IV =  0.1621397972684406\n",
      "LBT_ACCT_DEP_MNTH_LST_CLSR_QTY   IV =  0.1621397972684406\n",
      "LBT_ACCT_DEP_TD_BAL_RUB_AMT   IV =  0.12284674775971849\n",
      "LBT_ACCT_DEP_TOT_BAL_RUB_AMT   IV =  0.23914868542399784\n",
      "LBT_ACCT_TOT_BAL_PREV_RUB_AMT   IV =  0.42401023622674017\n",
      "LBT_ACCT_TOT_BAL_PREV_RUB001   IV =  0.42401023622674017\n",
      "LBT_SOCIAL_L3M_AVG_RUB_AMT   IV =  0.08542028407793212\n",
      "MAX_ARREAR   IV =  0.15562994571756497\n",
      "MAX_TR_RECEIPT_3M_RUR   IV =  0.21639190806883277\n",
      "MIN_APP_DAYS   IV =  0.08722452853086937\n"
     ]
    }
   ],
   "source": [
    "#Формируем сэмпл для разработки\n",
    "x_sample = df.copy()\n",
    "x_sample = x_sample.drop(['CONTRACT_SRC_CODE','SCORE_FINAL','BAD_12_FLAG90'], axis=1)\n",
    "#Целевая переменная\n",
    "y = df[\"BAD_12_FLAG90\"][df['BAD_12_FLAG90'].notnull()] \n",
    "#Процедура отбора переменных по критерию порогового IV\n",
    "var_list = iv_selection(x_sample,y,0.01)\n",
    "x_sample = x_sample[var_list]\n",
    "print('________________________________________________________________________________________________________________')\n",
    "#Выводим графики WOE по переменным\n",
    "for col in x_sample.columns: print_woe_graph(iv_table(binning(x_sample[col],y,max_bins=10,mode='normal'),y),col)\n",
    "print('________________________________________________________________________________________________________________')\n",
    "#Преобразуем в one-hot\n",
    "x_dev = dev_to_one_hot(x_sample,y)\n",
    "#Исключаем коррелирующие переменные\n",
    "x_dev = exclude_corr_factors(x_dev, 0.8)\n",
    "print('________________________________________________________________________________________________________________')\n",
    "#Строим логит регрессию\n",
    "model_logit = build_model(x_dev,y)\n",
    "#Выводим визуально получившуюся скоркарту\n",
    "scorecard = scorecard_view(x_dev.columns,model_logit,odds_X_to_one=100,odds_score=700,double_odds=25)\n",
    "print(scorecard)\n",
    "print('________________________________________________________________________________________________________________')\n",
    "#Выводим GINI скоркарты\n",
    "gini(model_logit,x_dev,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iv_var = iv_table(binning(x_sample.SibSp,y,max_bins=10,mode='normal'),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(x.columns)):\n",
    "    x_bin = binning(x[x.columns[i]],y,max_bins=8,mode='one-hot')\n",
    "    x_dev = pd.merge(x_dev,x_bin,left_index=True,right_index=True)\n",
    "del x_dev[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
