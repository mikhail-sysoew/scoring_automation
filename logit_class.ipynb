{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "\n",
    "\n",
    "class Scorecard():\n",
    "    def __init__(self, max_bins=16, minimum_leaf=0.025, corr_threshold=0.9, odds_X_to_one = 100, odds_score=700, double_odds=25):        \n",
    "        self.regressor=LogisticRegression() #Regression build method\n",
    "        self.x = pd.DataFrame() #Input sample\n",
    "        self.y = pd.DataFrame() #Targets\n",
    "        self.vars = []\n",
    "        self.vars_after_iv_cut = []\n",
    "        self.vars_after_corr_cut = []\n",
    "        self.vars_after_corr_cut_one_hot = []\n",
    "        self.var_list_types = {} #Types of variables\n",
    "        self.var_list_bins = {} #Binning of scorecard variables dictionary\n",
    "        self.scorecard = pd.DataFrame() #Final scorecard representation\n",
    "        self.iv_table = {} #information value tables for each variable\n",
    "        self.gini = int #Gini of model \n",
    "        self.logit_model = [] #model object for LogisticRegression\n",
    "        self.max_bins = max_bins #Regularization parameter. Maximum bins used in decision tree\n",
    "        self.minimum_leaf = minimum_leaf #Regularization parameter. Mininmum size of one leaf\n",
    "        self.column = ''\n",
    "        self.iv_table = {} #Dictionary which contains iv table for each variable\n",
    "        self.x_one_hot = pd.DataFrame() #Input sample in one-hot view\n",
    "        self.corr_threshold = corr_threshold\n",
    "        self.odds_X_to_one = odds_X_to_one \n",
    "        self.odds_score = odds_score\n",
    "        self.double_odds = double_odds\n",
    "        self.x_binned = pd.DataFrame()\n",
    "        self.x_corr_matrix = []\n",
    "        \n",
    "   \n",
    "  \n",
    "    #Learn model on sample\n",
    "    def fit(self,x,y,iv_threshold):        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.vars_after_iv_cut = []\n",
    "        self.x = self.x.reset_index()\n",
    "        self.y = self.y.reset_index()\n",
    "        del self.x[\"index\"]\n",
    "        del self.y[\"index\"]      \n",
    "        self.fill_vars_cats()   \n",
    "        print(\"Start excluding correlations on main sample\")\n",
    "        self.x_corr_matrix = self.x.corr()\n",
    "        self.exclude_corr_factors(mode='normal')   \n",
    "        print(\"Finish excluding correlations on main sample\")\n",
    "        print('Start binning columns...')\n",
    "        #fill all values of var_list_bins\n",
    "        for col in self.x.columns: \n",
    "            print('Binning: ',col)\n",
    "            self.binning(mode_forward='binning',mode_output='normal',column_name=col)  \n",
    "            #Filling IV table on current variable\n",
    "            df_t = pd.DataFrame(self.binning(mode_forward='forward',mode_output='normal',column_name=col))\n",
    "            df_t[\"y\"] = self.y\n",
    "            #df_t = df_t.rename(index=str, columns = {col:\"x\"})\n",
    "            df_iv =pd.DataFrame({'count': df_t.groupby(col)['y'].count(), \n",
    "                             'bad_rate': df_t.groupby(col)['y'].mean(),\n",
    "                             'total_goods': df_t.groupby(col)['y'].count() - df_t.groupby(col)['y'].sum(),\n",
    "                            'total_bads': df_t.groupby(col)['y'].sum() \n",
    "                             }).reset_index()\n",
    "            df_iv[\"cumm_bads\"] = df_iv['total_bads'].cumsum()\n",
    "            df_iv[\"cumm_goods\"] = df_iv['total_goods'].cumsum()\n",
    "            df_iv[\"cumm_total\"] = df_iv['count'].cumsum()\n",
    "            df_iv[\"per_bad\"] = df_iv[\"total_bads\"]/df_iv[\"cumm_bads\"].max()\n",
    "            df_iv[\"per_good\"] = df_iv[\"total_goods\"]/df_iv[\"cumm_goods\"].max()\n",
    "            df_iv[\"woe\"] = np.log((df_iv[\"per_good\"])/(df_iv[\"per_bad\"]+0.000000001))\n",
    "            iv = (df_iv[\"per_good\"] - df_iv[\"per_bad\"])*np.log((df_iv[\"per_good\"])/(df_iv[\"per_bad\"]+0.000000001))\n",
    "            df_iv[\"iv\"] = iv.sum()       \n",
    "            self.iv_table[col] = df_iv\n",
    "            if df_iv[\"iv\"].mean()>=iv_threshold: self.vars_after_iv_cut.append(col)\n",
    "            print('       IV = ', iv.sum())\n",
    "        #creating sample in one-hot view\n",
    "        self.x_one_hot = pd.DataFrame(self.x.index.values)       \n",
    "        for col in self.vars_after_iv_cut:          \n",
    "            self.x_one_hot = pd.merge(self.x_one_hot, pd.DataFrame(self.binning(mode_forward='forward',mode_output='one-hot',column_name=col)),left_index=True,right_index=True)\n",
    "        del self.x_one_hot[self.x_one_hot.columns[0]]\n",
    "        self.x = self.x[self.vars_after_iv_cut] \n",
    "        print('Exclude correlations on one-hot...')\n",
    "        self.exclude_corr_factors(mode='one-hot')   \n",
    "        print('Building regression...')\n",
    "        self.regressor.fit(self.x_one_hot,self.y)\n",
    "        self.scorecard_view()\n",
    "        \n",
    "    def predict_proba(self,x):\n",
    "        self.x = x        \n",
    "        self.x = x.reset_index()\n",
    "        del self.x[\"index\"]\n",
    "        self.x_binned = pd.DataFrame(self.x.index.values)\n",
    "        cols_to_delete = set(self.x.columns) - set(self.vars_after_iv_cut)\n",
    "        for c in cols_to_delete:\n",
    "            del self.x[c]\n",
    "        for col in self.vars_after_iv_cut:\n",
    "            self.x_binned = pd.merge(self.x_binned,pd.DataFrame(self.binning(mode_forward='forward',mode_output='one-hot',column_name = col)),left_index=True,right_index=True)\n",
    "            #del x_binned[x_binned.columns[0]]\n",
    "        cols_to_delete = set(self.x_binned.columns) - set(self.scorecard[\"Variable\"])\n",
    "        for c in cols_to_delete:\n",
    "            del self.x_binned[c]\n",
    "        self.x_binned = self.x_binned.reindex_axis(sorted(self.x_binned), axis=1) \n",
    "        return self.regressor.predict_proba(self.x_binned)[:,1]\n",
    "        \n",
    "    def predict_score(self,x):\n",
    "        y_pred = self.predict_proba(x)\n",
    "        bias = self.odds_score - self.double_odds*np.log(self.odds_X_to_one)/np.log(2)   \n",
    "        odds = self.double_odds/np.log(2)         \n",
    "        return bias+odds*np.log(1/y_pred-1)  \n",
    "      \n",
    "    \n",
    "    def scorecard_view(self):\n",
    "      #  print('Printing scorecard...')\n",
    "        self.scorecard=[]\n",
    "        cols = np.array('Intercept')\n",
    "        cols = np.append(cols,np.array(self.vars_after_corr_cut_one_hot))\n",
    "        vals = np.array(self.regressor.intercept_)\n",
    "        vals = np.append(vals,np.array(self.regressor.coef_))\n",
    "        self.scorecard = pd.DataFrame(cols)\n",
    "        self.scorecard.rename(columns={0: 'Variable'},inplace=True)\n",
    "        self.scorecard[\"Regression_coef\"] = pd.DataFrame(vals)\n",
    "        b = self.double_odds/np.log(2)\n",
    "        a = self.odds_score - b*np.log(self.odds_X_to_one)    \n",
    "        self.scorecard[\"Score\"] = -self.scorecard[\"Regression_coef\"]*b\n",
    "        self.scorecard[\"Score\"][0] = self.scorecard[\"Score\"][0]+a\n",
    "        self.scorecard[\"Score\"] = round(self.scorecard[\"Score\"],2)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #Exclude correlations. Fill vars_after_corr_cut. Exclude correlated columns from x_one_hot\n",
    "    def exclude_corr_factors(self,mode):\n",
    "        if mode=='normal': x_corr = self.x_corr_matrix\n",
    "        if mode=='one-hot': x_corr = self.x_one_hot.corr()    \n",
    "        cols_drop=[]\n",
    "        for i in range(0,len(x_corr.columns)):\n",
    "            if x_corr.columns[i] not in cols_drop:\n",
    "                for j in range(i+1,len(x_corr.columns)):        \n",
    "                    if abs(x_corr.iloc[i][j])>self.corr_threshold: cols_drop.append(x_corr.iloc[j].name)\n",
    "        if mode=='normal': \n",
    "            self.vars_after_corr_cut = list(set(self.x.columns) - set(cols_drop))\n",
    "            self.vars_after_corr_cut.sort()\n",
    "        if mode=='one-hot': \n",
    "            self.vars_after_corr_cut_one_hot = list(set(self.x_one_hot.columns) - set(cols_drop))\n",
    "            self.vars_after_corr_cut_one_hot.sort()            \n",
    "        print('Dropped columns:', cols_drop)\n",
    "        if mode=='normal': self.x = self.x[self.vars_after_corr_cut]\n",
    "        if mode=='one-hot': self.x_one_hot = self.x_one_hot[self.vars_after_corr_cut_one_hot]\n",
    "            \n",
    "        \n",
    "    \n",
    "    #Input - one variable name \n",
    "    #Output - optimal binning, builded on decision tree. Maximum number of bins = max_bins\n",
    "    def split_numeric(self,column_name):  \n",
    "        x_train_t = np.array(self.x[column_name][self.x[column_name].notnull()]) #Exclude nulls \n",
    "        y_train_t = np.array(self.y[self.x[column_name].notnull()])\n",
    "        y_train_t = y_train_t.reshape(len(y_train_t),)\n",
    "        x_train_t = x_train_t.reshape(x_train_t.shape[0], 1) #Need for DecisionTreeClassifier\n",
    "        m_depth = int(np.log2(self.max_bins)) + 1 #Maximum tree depth\n",
    "        bad_rate = y_train_t.mean()\n",
    "        start = 1\n",
    "        cv_scores = []\n",
    "        cv = 3\n",
    "        for i in range(start,m_depth): #Loop over all tree depth. CV on the each step\n",
    "            d_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=i, min_samples_leaf=self.minimum_leaf)\n",
    "            scores = cross_val_score(d_tree, x_train_t, y_train_t, cv=cv,scoring='roc_auc')   \n",
    "            cv_scores.append(scores.mean())        \n",
    "        best = np.argmax(cv_scores) + start #Criterion - maximum GINI on validation set        \n",
    "        final_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=best, min_samples_leaf=0.025) #Build final tree\n",
    "        final_tree.fit(x_train_t, y_train_t)\n",
    "        #Final tree\n",
    "        opt_bins = final_tree.tree_.threshold[final_tree.tree_.feature >= 0]        \n",
    "        opt_bins = np.append(opt_bins,max(x_train_t)+1)#Add right border\n",
    "        opt_bins = np.append(opt_bins,min(x_train_t)-1)#Add left border\n",
    "        opt_bins = np.sort(opt_bins)    \n",
    "        return opt_bins #Return optimal binning\n",
    "    \n",
    "    #Split categorial variable. Grouping variable for regularization.\n",
    "    #Input = column name\n",
    "    #Output : add to var_list_bins binned variable as dictionary\n",
    "    def split_categorial(self,column_name):\n",
    "        #One-hot encoding\n",
    "        self.x[column_name] = self.x[column_name].fillna('MISSING')\n",
    "        x_cat = pd.get_dummies(self.x[column_name],prefix = self.x[column_name].name)\n",
    "        y_t = np.array(self.y)\n",
    "        y_t = y_t.reshape(len(y_t),)\n",
    "        bad_rate = y_t.mean()\n",
    "        max_bins = max(self.x[column_name].nunique(),20)\n",
    "        #Classification by decision tree\n",
    "        m_depth = max_bins+1\n",
    "        start = 1\n",
    "        cv_scores = []\n",
    "        cv = 3\n",
    "        for i in range(start,m_depth):\n",
    "            d_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=i, min_samples_leaf=self.minimum_leaf) \n",
    "            scores = cross_val_score(d_tree, x_cat, y_t, cv=cv,scoring='roc_auc') \n",
    "            cv_scores.append(scores.mean())\n",
    "        #    print(\"Number of bins = \", i,\"; GINI = \",2*scores.mean()-1)\n",
    "        best = np.argmax(cv_scores) + start #Choose maximizing GINI on validation dataset\n",
    "        #print(\"Optimal number of bins: \",best, \"; GINI = \",2*max(cv_scores)-1)\n",
    "        final_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=best, min_samples_leaf=0.025) #Build final tree\n",
    "        final_tree.fit(x_cat, self.y)\n",
    "\n",
    "        #Get leafes names\n",
    "        x_l = final_tree.apply(x_cat)\n",
    "        tmp = pd.DataFrame(self.x[column_name])\n",
    "        tmp[\"LEAF\"] = x_l\n",
    "\n",
    "        #Make dictionary with optimal binning\n",
    "        d = {}\n",
    "        for leaf in tmp[\"LEAF\"].unique():\n",
    "            d[leaf]=str(self.x[column_name][tmp[\"LEAF\"]==leaf].unique())   \n",
    "        tmp[\"x_num\"] = tmp[\"LEAF\"].apply(lambda x: d.get(x))\n",
    "        return d\n",
    "   \n",
    "    #Define variable category - numeric or categorial\n",
    "    #Input - column name\n",
    "    #Output - numeric or cat\n",
    "    def check_type(self,column_name):\n",
    "        from pandas.api.types import is_string_dtype\n",
    "        from pandas.api.types import is_numeric_dtype   \n",
    "        #delete nulls\n",
    "        tmp_var = self.x[column_name][self.x[column_name].notnull()]\n",
    "        #If number of uniques<=4 then type = categorial\n",
    "        if tmp_var.nunique()<=4: return 'cat'\n",
    "        elif is_numeric_dtype(tmp_var): return 'numeric'\n",
    "        else: return 'cat'\n",
    "    \n",
    "    #Fill variable var_list_cats\n",
    "    def fill_vars_cats(self):\n",
    "        from pandas.api.types import is_string_dtype\n",
    "        from pandas.api.types import is_numeric_dtype \n",
    "        for col in self.x[self.x.columns]:\n",
    "            if self.check_type(col)=='numeric': self.var_list_types[col]='numeric'\n",
    "            if self.check_type(col)=='cat': \n",
    "                self.var_list_types[col]='cat'\n",
    "                if (self.x[col].nunique()<=4)&(is_numeric_dtype(self.x[col])): self.x[col] = self.x[col].apply(lambda x: 'cat_'+str(x))\n",
    "                \n",
    "    \n",
    "    #Add leading zeros to names\n",
    "    def zero_pad(self,x):\n",
    "        if str(x)=='MISSING': return '000'\n",
    "        if len(str(x))==3: return str('00'+str(x))[:-2]+': '\n",
    "        if len(str(x))==4: return str('0'+str(x))[:-2]+': '\n",
    "        if len(str(x))==5: str(x)[:-2]+': '\n",
    "    \n",
    "    #Naming for categories by rank\n",
    "    def make_dict(x):        \n",
    "        x_dict = x.groupby(0)[\"val\"].min().fillna(0).sort_values().reset_index().rename(index=str, columns={0: \"x\"})\n",
    "        x_dict['rownum'] = x_dict['val'].rank(method='first', na_option='top')\n",
    "        x_dict['rownum'] = x_dict['rownum'].apply(zero_pad)\n",
    "        x_dict['x_num'] = x_dict[\"rownum\"].map(str)+x_dict[\"x\"].map(str)\n",
    "        del x_dict['val']\n",
    "        del x_dict['rownum']\n",
    "        return x_dict   \n",
    "    \n",
    "    #Binning procedure\n",
    "    #Return binned sample. Has two modes - one-hot and norma;\n",
    "    #Inputs \n",
    "    #      x - sample\n",
    "    #      y - targets\n",
    "    #      max_bins - maximum number of bins\n",
    "    #      optimal_bins - for mode_output = 'normal' or 'one-hot' using as input for feed forward\n",
    "    #                     for mode_forward='binning' calculating of optimal bins\n",
    "    #                         mode_forward='forward' calculating outputs using optimals bins as input \n",
    "    #\n",
    "    \n",
    "    #Need for feed forward categorial variables\n",
    "    #Take value from dictionary var_list_bins and answer if current value is in list\n",
    "    #If yes - return list\n",
    "    \n",
    "    \n",
    "    def forward_cat(self,x):\n",
    "        for i in self.var_list_bins[self.column].keys():\n",
    "            if str(x) in self.var_list_bins[self.column][i]:\n",
    "                return str(self.var_list_bins[self.column][i]) \n",
    "    \n",
    "    def binning(self,mode_output,mode_forward,column_name):\n",
    "        variable_type = self.var_list_types[column_name]\n",
    "        if (variable_type=='numeric')&(mode_forward=='forward'):         \n",
    "            #Вспомогательная переменная, хранящая разбиения по непустым значениям\n",
    "            x_bin_t = pd.cut(self.x[column_name][self.x[column_name].notnull()],bins=self.var_list_bins[column_name])    \n",
    "            #Вспомогательная переменная, хранящая one-hot по непустым значениям\n",
    "            x_bin = pd.get_dummies(x_bin_t,prefix=self.x[column_name].name,drop_first=True)\n",
    "            #Добавляем колонку с пустыми значениями\n",
    "            x_bin[self.x[column_name].name+'_ISNULL']=0\n",
    "            x_null = pd.DataFrame(self.x[column_name][self.x[column_name].isnull()])\n",
    "            for i in x_bin.columns:\n",
    "                x_null[i]=0\n",
    "            x_null[self.x[column_name].name+'_ISNULL']=1\n",
    "            del x_null[self.x[column_name].name]\n",
    "            #Если нет NULL то колонку с dummy is null удаляем   \n",
    "            if len(self.x[column_name][self.x[column_name].isnull()])==0:\n",
    "                del x_null[self.x[column_name].name+'_ISNULL']\n",
    "                del x_bin[self.x[column_name].name+'_ISNULL']\n",
    "            #Вспомогательная переменная, которая хранит узкий и широкий вид, включая пустые значения    \n",
    "            x_pivot = pd.concat([x_bin_t,pd.DataFrame(self.x[column_name][self.x[column_name].isnull()])]).sort_index(axis=0)        \n",
    "            del x_pivot[self.x[column_name].name]\n",
    "            #Заполняем пустые значения MISSING\n",
    "            x_pivot = x_pivot.fillna('MISSING')\n",
    "            x_pivot['val'] = self.x[column_name]        \n",
    "            #Добавляем категориям индекс (создается справочник)           \n",
    "            x_dict = x_pivot.groupby(0)[\"val\"].min().fillna(0).sort_values().reset_index().rename(index=str, columns={0: \"x\"})\n",
    "            x_dict['rownum'] = x_dict['val'].rank(method='first', na_option='top')\n",
    "            x_dict['rownum'] = x_dict['rownum'].apply(self.zero_pad)\n",
    "            x_dict[column_name] = x_dict[\"rownum\"].map(str)+x_dict[\"x\"].map(str)\n",
    "            del x_dict['val']\n",
    "            del x_dict['rownum']\n",
    "            x_d =  x_dict   \n",
    "            x_pivot[\"rownum\"] = x_pivot.index.values\n",
    "            x_pivot = pd.merge(x_pivot,x_d,left_on=0,right_on=\"x\").sort_values(by='rownum').reset_index()[column_name]\n",
    "            #Джойним значения со справочником, удаляем исходные        \n",
    "            if mode_output=='one-hot': return pd.concat([x_bin,x_null]).sort_index(axis=0) #Возвращаем в виде on-hot                            \n",
    "            if mode_output=='normal': return x_pivot #Возвращаем в \"длинном и узком\" виде               \n",
    "        if (variable_type=='cat')&(mode_forward=='forward'): \n",
    "            ####################INPUT CODE HERE#####################\n",
    "            if mode_output=='normal': \n",
    "                self.column = column_name\n",
    "                return self.x[column_name].apply(self.forward_cat)\n",
    "            if mode_output=='one-hot': \n",
    "                self.column = column_name\n",
    "                return pd.get_dummies(self.x[column_name].apply(self.forward_cat), drop_first=True,prefix=self.x[column_name].name)\n",
    "        if (variable_type=='numeric')&(mode_forward=='binning'):\n",
    "            self.var_list_bins[column_name] = self.split_numeric(column_name)\n",
    "        if (variable_type=='cat')&(mode_forward=='binning'):                \n",
    "            self.var_list_bins[column_name] = self.split_categorial(column_name)\n",
    "            #x_bin = self.split_categorial(column_name)          \n",
    "            #if mode_output=='one-hot': return pd.get_dummies(x_bin,prefix=self.x[column_name].name,drop_first=True)\n",
    "            #if mode_output=='normal': return pd.DataFrame(x_bin)\n",
    "    \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/cc_sample.txt',sep=';',decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.copy()\n",
    "x = x[x['BAD_12_FLAG90'].notnull()]\n",
    "y = x['BAD_12_FLAG90']\n",
    "x = x.drop(['BAD_12_FLAG90','SCORE_FINAL','CONTRACT_SRC_CODE'],axis=1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start excluding correlations on main sample\n",
      "Dropped columns: ['CNT_TR_PUBL_UTIL_6M', 'CRD_DC_POS_HEALTHCARE_RUB001', 'LBT_ACCT_DEP_MNTH_LST_CLSR_QTY', 'LBT_ACCT_DEP_TOT_BAL_RUB_AMT', 'LBT_ACCT_TOT_BAL_PREV_RUB001', 'RATE_TR_ALL_7D_6M', 'RATE_TR_PAY_L3_6M']\n",
      "Finish excluding correlations on main sample\n",
      "Start binning columns...\n",
      "Binning:  AVG_TERM_FACT\n",
      "       IV =  0.07753316474188539\n",
      "Binning:  CMPN_DM_AVAIL_NFLAG\n",
      "       IV =  0.060266096687580026\n",
      "Binning:  CMPN_EMAIL_AVAIL_NFLAG\n",
      "       IV =  0.06827384747065326\n",
      "Binning:  CMPN_TM_AVAIL_NFLAG\n",
      "       IV =  0.11146630802930632\n",
      "Binning:  CNT_AGR_OPEN\n",
      "       IV =  0.08236774536959401\n",
      "Binning:  CNT_AGR_WO_ARREAR_TO_CNT\n",
      "       IV =  0.11051896074491833\n",
      "Binning:  CNT_OPENED_6M\n",
      "       IV =  0.10529126096673581\n",
      "Binning:  CNT_OPENED_6M1Y\n",
      "       IV =  0.07662821690326752\n",
      "Binning:  CNT_TR_CARD_TRANS_1M\n",
      "       IV =  0.08608407449679625\n",
      "Binning:  CNT_TR_CASH_1M\n",
      "       IV =  0.16509297779983234\n",
      "Binning:  CNT_TR_CASH_3M\n",
      "       IV =  0.19120537887823397\n",
      "Binning:  CNT_TR_MEDICINE_6M\n",
      "       IV =  0.11271500272760152\n",
      "Binning:  CNT_TR_PUBL_UTIL_1M\n",
      "       IV =  0.07343849384546416\n",
      "Binning:  CNT_TR_PUBL_UTIL_3M\n",
      "       IV =  0.10326895784008708\n",
      "Binning:  CNT_TR_RELAX_6M\n",
      "       IV =  0.06782849828042914\n",
      "Binning:  CNT_TR_REPAIR_6M\n",
      "       IV =  0.08334884325594688\n",
      "Binning:  CRD_CC_EVER_NFLAG\n",
      "       IV =  0.13097440890315293\n",
      "Binning:  CRD_DC_MNTH_SNC_OPEN_QTY\n",
      "       IV =  0.14662704915378091\n",
      "Binning:  CRD_DC_PAYROLL_PMT_NFLAG\n",
      "       IV =  0.11166226029442866\n",
      "Binning:  CRD_DC_POS_HEALTHCARE_RUB_AMT\n",
      "       IV =  0.08259231904874256\n",
      "Binning:  CRD_DC_POS_HOME_REPAIR_QTY\n",
      "       IV =  0.04955138558851198\n",
      "Binning:  CRD_DC_SOCIAL_PMT_NFLAG\n",
      "       IV =  0.06103915856496098\n",
      "Binning:  CRD_OTF_DC_CASH_QTY\n",
      "       IV =  0.13870941634882203\n",
      "Binning:  CRD_OTF_DC_TOTAL_QTY\n",
      "       IV =  0.26798523129945123\n",
      "Binning:  CRD_OTF_FEE_QTY\n",
      "       IV =  0.17942770231746463\n",
      "Binning:  CRD_POS_AUTO_RUB_3M_AMT\n",
      "       IV =  0.04620664475125721\n",
      "Binning:  CRD_POS_TOURISM_RUB_3M_AMT\n",
      "       IV =  0.013665044172450798\n",
      "Binning:  CRD_TRX_DC_CASH_3M_QTY\n",
      "       IV =  0.23891920117855112\n",
      "Binning:  CRD_TRX_DC_POS_RTRN_6M_QTY\n",
      "       IV =  0.021792042547564526\n",
      "Binning:  DEP_TOPUP_12M_AVG_RUB_AMT\n",
      "       IV =  0.25549652002498885\n",
      "Binning:  FIRST_OPENED\n",
      "       IV =  0.13743119595603245\n",
      "Binning:  LAST_DEL_DAYS_PRC_MAX\n",
      "       IV =  0.006564923970253693\n",
      "Binning:  LAST_OPENED\n",
      "       IV =  0.11810967995119782\n",
      "Binning:  LBT_ACCT_DEP_CA_BAL_RUB_AMT\n",
      "       IV =  0.15643614753075016\n",
      "Binning:  LBT_ACCT_DEP_MNTH_LST_CLS001\n",
      "       IV =  0.16685839009462616\n",
      "Binning:  LBT_ACCT_DEP_TD_BAL_RUB_AMT\n",
      "       IV =  0.12640169112510158\n",
      "Binning:  LBT_ACCT_TOT_BAL_PREV_RUB_AMT\n",
      "       IV =  0.4206582481986563\n",
      "Binning:  LBT_SOCIAL_L3M_AVG_RUB_AMT\n",
      "       IV =  0.08282986504662909\n",
      "Binning:  MAX_ARREAR\n",
      "       IV =  0.1531585287040482\n",
      "Binning:  MAX_TR_RECEIPT_3M_RUR\n",
      "       IV =  0.22063378648053433\n",
      "Binning:  MIN_APP_DAYS\n"
     ]
    }
   ],
   "source": [
    "s = Scorecard()\n",
    "s.fit(x_train,y_train,iv_threshold=0.01)\n",
    "s.predict_proba(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
