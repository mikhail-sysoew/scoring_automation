{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "\n",
    "class Scorecard():\n",
    "    def __init__(self,x,y, max_bins=8, minimum_leaf=0.025, corr_threshold=0.8, odds_X_to_one = 100, odds_score=700, double_odds=25):        \n",
    "        self.regressor=LogisticRegression() #Regression build method\n",
    "        self.x = x #Input sample\n",
    "        self.y = y #Targets\n",
    "        self.vars = []\n",
    "        self.vars_after_iv_cut = []\n",
    "        self.vars_after_corr_cut = []\n",
    "        self.var_list_types = {} #Types of variables\n",
    "        self.var_list_bins = {} #Binning of scorecard variables dictionary\n",
    "        self.scorecard = pd.DataFrame() #Final scorecard representation\n",
    "        self.iv_table = {} #information value tables for each variable\n",
    "        self.gini = int #Gini of model \n",
    "        self.logit_model = [] #model object for LogisticRegression\n",
    "        self.max_bins = max_bins #Regularization parameter. Maximum bins used in decision tree\n",
    "        self.minimum_leaf = minimum_leaf #Regularization parameter. Mininmum size of one leaf\n",
    "        self.column = ''\n",
    "        self.iv_table = {} #Dictionary which contains iv table for each variable\n",
    "        self.x_one_hot = pd.DataFrame() #Input sample in one-hot view\n",
    "        self.corr_threshold = corr_threshold\n",
    "        self.odds_X_to_one = odds_X_to_one \n",
    "        self.odds_score = odds_score\n",
    "        self.double_odds = double_odds\n",
    "        self.x_binned = pd.DataFrame()\n",
    "        self.fill_vars_cats()\n",
    "        \n",
    "    \n",
    "    #Learn model on sample\n",
    "    def fit(self,x,y,iv_treshold):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        #fill all values of var_list_bins\n",
    "        for col in self.x.columns:\n",
    "            print(col)\n",
    "            self.binning(mode_forward='binning',mode_output='normal',column_name=col)  \n",
    "            #Filling IV table on current variable\n",
    "            df_t = pd.DataFrame(self.binning(mode_forward='forward',mode_output='normal',column_name=col))\n",
    "            df_t[\"y\"] = self.y\n",
    "            #df_t = df_t.rename(index=str, columns = {col:\"x\"})\n",
    "            df_iv =pd.DataFrame({'count': df_t.groupby(col)['y'].count(), \n",
    "                             'bad_rate': df_t.groupby(col)['y'].mean(),\n",
    "                             'total_goods': df_t.groupby(col)['y'].count() - df_t.groupby(col)['y'].sum(),\n",
    "                            'total_bads': df_t.groupby(col)['y'].sum() \n",
    "                             }).reset_index()\n",
    "            df_iv[\"cumm_bads\"] = df_iv['total_bads'].cumsum()\n",
    "            df_iv[\"cumm_goods\"] = df_iv['total_goods'].cumsum()\n",
    "            df_iv[\"cumm_total\"] = df_iv['count'].cumsum()\n",
    "            df_iv[\"per_bad\"] = df_iv[\"total_bads\"]/df_iv[\"cumm_bads\"].max()\n",
    "            df_iv[\"per_good\"] = df_iv[\"total_goods\"]/df_iv[\"cumm_goods\"].max()\n",
    "            df_iv[\"woe\"] = np.log((df_iv[\"per_good\"])/(df_iv[\"per_bad\"]+0.000000001))\n",
    "            iv = (df_iv[\"per_good\"] - df_iv[\"per_bad\"])*np.log((df_iv[\"per_good\"])/(df_iv[\"per_bad\"]+0.000000001))\n",
    "            df_iv[\"iv\"] = iv.sum()       \n",
    "            self.iv_table[col] = df_iv\n",
    "            if df_iv[\"iv\"].mean()>=iv_treshold: self.vars_after_iv_cut.append(col)\n",
    "        #creating sample in one-hot view\n",
    "        self.x_one_hot = pd.DataFrame(self.x.index.values)\n",
    "        for col in self.vars_after_iv_cut:\n",
    "            self.x_one_hot = pd.merge(self.x_one_hot, pd.DataFrame(self.binning(mode_forward='forward',mode_output='one-hot',column_name=col)),left_index=True,right_index=True)\n",
    "            del self.x_one_hot[self.x_one_hot.columns[0]]\n",
    "        self.x = self.x[self.vars_after_iv_cut]\n",
    "        self.exclude_corr_factors()                \n",
    "        self.regressor.fit(self.x_one_hot,self.y)\n",
    "        self.scorecard_view()\n",
    "        \n",
    "    def predict(self,x, mode):\n",
    "        self.x = x\n",
    "        self.x_binned = pd.DataFrame(self.x.index.values)\n",
    "        for col in x.columns:\n",
    "            self.x_binned = pd.merge(self.x_binned,pd.DataFrame(self.binning(mode_forward='forward',mode_output='one_hot',column_name = col)),left_index=True,right_index=True)\n",
    "            #del x_binned[x_binned.columns[0]]\n",
    "        return self.regressor.predict_proba(self.x_binned)[:,1]\n",
    "    \n",
    "    def scorecard_view(self):\n",
    "      #  print('Printing scorecard...')\n",
    "        cols = np.array('Intercept')\n",
    "        cols = np.append(cols,np.array(self.vars_after_corr_cut))\n",
    "        vals = np.array(self.regressor.intercept_)\n",
    "        vals = np.append(vals,np.array(self.regressor.coef_))\n",
    "        self.scorecard = pd.DataFrame(self.vars_after_corr_cut)\n",
    "        self.scorecard.rename(columns={0: 'Variable'},inplace=True)\n",
    "        self.scorecard[\"Regression_coef\"] = pd.DataFrame(vals)\n",
    "        b = self.double_odds/np.log(2)\n",
    "        a = self.odds_score - b*np.log(self.odds_X_to_one)    \n",
    "        self.scorecard[\"Score\"] = self.scorecard[\"Regression_coef\"]*b\n",
    "        self.scorecard[\"Score\"][0] = self.scorecard[\"Score\"][0]+a\n",
    "        self.scorecard[\"Score\"] = round(self.scorecard[\"Score\"],2)\n",
    "        \n",
    "    \n",
    "    \n",
    "    #Exclude correlations. Fill vars_after_corr_cut. Exclude correlated columns from x_one_hot\n",
    "    def exclude_corr_factors(self):\n",
    "        x_corr = self.x_one_hot.corr()\n",
    "        #Оставляем только колонки - потенциальные кандидаты на исключение (хотя бы одно значение корреляции выше трешхолда)\n",
    "        col_list=[]    \n",
    "        for i in range(len(x_corr.columns)):\n",
    "            #Заменяем диагональные значения на 0    \n",
    "            x_corr[x_corr.columns[i]][x_corr[x_corr.columns[i]].index.values[i]] = 0\n",
    "            #Если в колонке найдено, хотя бы одно значение с корреляцией больше трешхолда, добавляем ее в лист\n",
    "            if max(abs(x_corr[x_corr.columns[i]]))>self.corr_threshold: col_list.append(x_corr.columns[i])\n",
    "        #Оставляем только те колонки, из которых нужно выбрать которые выкинуть из-за корреляций            \n",
    "        x_dev_drop =  self.x_one_hot[col_list]\n",
    "        #Строим корреляционную матрицу из оставшихся\n",
    "        x_c = x_dev_drop.corr()\n",
    "        #Пустой список\n",
    "        corr_list = []\n",
    "        corr_list.append([])\n",
    "        exclude_iteration = 0\n",
    "        var_list = [0,1]\n",
    "        #Заполняем диагональ нулями\n",
    "        for i in range(len(x_c.columns)):        \n",
    "            x_c[x_c.columns[i]][x_c[x_c.columns[i]].index.values[i]] = 0\n",
    "        while len(var_list)>1&len(x_c)>0:\n",
    "            for i in range(len(x_c.columns)):        \n",
    "                x_c[x_c.columns[i]][x_c[x_c.columns[i]].index.values[i]] = 0\n",
    "            #Если нашли хотя бы одну колонку, которая коррелирует с первой, создаем пару в corr_list и записываем туда первую колонку\n",
    "            if max(abs(x_c[x_c.columns[0]]))>=self.corr_threshold:     \n",
    "                corr_list[exclude_iteration].append(x_c.columns[0])\n",
    "            #Пробегаемся по всем колонкам\n",
    "                for i in range(len(x_c.columns)):\n",
    "            #Записываем в пару к первой все коррелирующие с ней колонки\n",
    "                    if abs(x_c[x_c.columns[0]].iloc[i])>=self.corr_threshold:\n",
    "                        corr_list[exclude_iteration].append(x_c.columns[i])\n",
    "                #Выкидываем все колонки, которые коррелируют с первой\n",
    "                var_list = [x for x in x_c.columns.values if x not in corr_list[exclude_iteration]]\n",
    "                x_dev_drop = x_dev_drop[var_list]\n",
    "                x_c = x_dev_drop.corr()\n",
    "                corr_list.append([])\n",
    "                exclude_iteration = exclude_iteration+1\n",
    "                print(\"Excluding correlations. Iteration = \",exclude_iteration,\"Corr list: \", corr_list)\n",
    "        #После обработки corr_list содержит все списки коррелирующих колонок. Из каждого списка оставляем только одну\n",
    "        cols_to_drop=[] #Список колонок, которые надо выкинуть\n",
    "        for i in range(len(corr_list)):\n",
    "            for j in range(len(corr_list[i])):\n",
    "                if j!=0: \n",
    "                    cols_to_drop.append(corr_list[i][j])\n",
    "        #Оставляем в исходном списке только колонки не из col_to_drop\n",
    "        exclude_list = [x for x in self.x_one_hot.columns.values if x not in cols_to_drop]\n",
    "        self.x_one_hot = self.x_one_hot[exclude_list]\n",
    "        self.vars_after_corr_cut = exclude_list\n",
    "        \n",
    "    \n",
    "    #Input - one variable name \n",
    "    #Output - optimal binning, builded on decision tree. Maximum number of bins = max_bins\n",
    "    def split_numeric(self,column_name):  \n",
    "        x_train_t = np.array(self.x[column_name][self.x[column_name].notnull()]) #Exclude nulls \n",
    "        y_train_t = np.array(self.y[self.x[column_name].notnull()])\n",
    "        x_train_t = x_train_t.reshape(x_train_t.shape[0], 1) #Need for DecisionTreeClassifier\n",
    "        m_depth = int(np.log2(self.max_bins)) + 1 #Maximum tree depth\n",
    "        bad_rate = y.mean()\n",
    "        start = 1\n",
    "        cv_scores = []\n",
    "        cv = 3\n",
    "        for i in range(start,m_depth): #Loop over all tree depth. CV on the each step\n",
    "            d_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=i, min_samples_leaf=self.minimum_leaf)\n",
    "            scores = cross_val_score(d_tree, x_train_t, y_train_t, cv=cv,scoring='roc_auc')   \n",
    "            cv_scores.append(scores.mean())        \n",
    "        best = np.argmax(cv_scores) + start #Criterion - maximum GINI on validation set        \n",
    "        final_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=best, min_samples_leaf=0.025) #Build final tree\n",
    "        final_tree.fit(x_train_t, y_train_t)\n",
    "        #Final tree\n",
    "        opt_bins = final_tree.tree_.threshold[final_tree.tree_.feature >= 0]        \n",
    "        opt_bins = np.append(opt_bins,max(x_train_t)+1)#Add right border\n",
    "        opt_bins = np.append(opt_bins,min(x_train_t)-1)#Add left border\n",
    "        opt_bins = np.sort(opt_bins)    \n",
    "        return opt_bins #Return optimal binning\n",
    "    \n",
    "    #Split categorial variable. Grouping variable for regularization.\n",
    "    #Input = column name\n",
    "    #Output : add to var_list_bins binned variable as dictionary\n",
    "    def split_categorial(self,column_name):\n",
    "        #One-hot encoding\n",
    "        self.x[column_name] = self.x[column_name].fillna('MISSING')\n",
    "        x_cat = pd.get_dummies(self.x[column_name],prefix = self.x[column_name].name)\n",
    "        bad_rate = self.y.mean()\n",
    "        max_bins = max(self.x[column_name].nunique(),20)\n",
    "        #Classification by decision tree\n",
    "        m_depth = max_bins+1\n",
    "        start = 1\n",
    "        cv_scores = []\n",
    "        cv = 3\n",
    "        for i in range(start,m_depth):\n",
    "            d_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=i, min_samples_leaf=self.minimum_leaf) \n",
    "            scores = cross_val_score(d_tree, x_cat, self.y, cv=cv,scoring='roc_auc') \n",
    "            cv_scores.append(scores.mean())\n",
    "        #    print(\"Number of bins = \", i,\"; GINI = \",2*scores.mean()-1)\n",
    "        best = np.argmax(cv_scores) + start #Choose maximizing GINI on validation dataset\n",
    "        #print(\"Optimal number of bins: \",best, \"; GINI = \",2*max(cv_scores)-1)\n",
    "        final_tree = tree.DecisionTreeClassifier(criterion='gini', max_depth=best, min_samples_leaf=0.025) #Build final tree\n",
    "        final_tree.fit(x_cat, self.y)\n",
    "\n",
    "        #Get leafes names\n",
    "        x_l = final_tree.apply(x_cat)\n",
    "        tmp = pd.DataFrame(self.x[column_name])\n",
    "        tmp[\"LEAF\"] = x_l\n",
    "\n",
    "        #Make dictionary with optimal binning\n",
    "        d = {}\n",
    "        for leaf in tmp[\"LEAF\"].unique():\n",
    "            d[leaf]=str(self.x[column_name][tmp[\"LEAF\"]==leaf].unique())   \n",
    "        tmp[\"x_num\"] = tmp[\"LEAF\"].apply(lambda x: d.get(x))\n",
    "        return d\n",
    "   \n",
    "    #Define variable category - numeric or categorial\n",
    "    #Input - column name\n",
    "    #Output - numeric or cat\n",
    "    def check_type(self,column_name):\n",
    "        from pandas.api.types import is_string_dtype\n",
    "        from pandas.api.types import is_numeric_dtype   \n",
    "        #delete nulls\n",
    "        tmp_var = self.x[column_name][self.x[column_name].notnull()]\n",
    "        #If number of uniques<=4 then type = categorial\n",
    "        if tmp_var.nunique()<=4: return 'cat'\n",
    "        elif is_numeric_dtype(tmp_var): return 'numeric'\n",
    "        else: return 'cat'\n",
    "    \n",
    "    #Fill variable var_list_cats\n",
    "    def fill_vars_cats(self):\n",
    "        from pandas.api.types import is_string_dtype\n",
    "        from pandas.api.types import is_numeric_dtype \n",
    "        for col in self.x[self.x.columns]:\n",
    "            if self.check_type(col)=='numeric': self.var_list_types[col]='numeric'\n",
    "            if self.check_type(col)=='cat': \n",
    "                self.var_list_types[col]='cat'\n",
    "                if (self.x[col].nunique()<=4)&(is_numeric_dtype(self.x[col])): self.x[col] = self.x[col].apply(lambda x: 'cat_'+str(x))\n",
    "                \n",
    "    \n",
    "    #Add leading zeros to names\n",
    "    def zero_pad(self,x):\n",
    "        if str(x)=='MISSING': return '000'\n",
    "        if len(str(x))==3: return str('00'+str(x))[:-2]+': '\n",
    "        if len(str(x))==4: return str('0'+str(x))[:-2]+': '\n",
    "        if len(str(x))==5: str(x)[:-2]+': '\n",
    "    \n",
    "    #Naming for categories by rank\n",
    "    def make_dict(x):        \n",
    "        x_dict = x.groupby(0)[\"val\"].min().fillna(0).sort_values().reset_index().rename(index=str, columns={0: \"x\"})\n",
    "        x_dict['rownum'] = x_dict['val'].rank(method='first', na_option='top')\n",
    "        x_dict['rownum'] = x_dict['rownum'].apply(zero_pad)\n",
    "        x_dict['x_num'] = x_dict[\"rownum\"].map(str)+x_dict[\"x\"].map(str)\n",
    "        del x_dict['val']\n",
    "        del x_dict['rownum']\n",
    "        return x_dict   \n",
    "    \n",
    "    #Binning procedure\n",
    "    #Return binned sample. Has two modes - one-hot and norma;\n",
    "    #Inputs \n",
    "    #      x - sample\n",
    "    #      y - targets\n",
    "    #      max_bins - maximum number of bins\n",
    "    #      optimal_bins - for mode_output = 'normal' or 'one-hot' using as input for feed forward\n",
    "    #                     for mode_forward='binning' calculating of optimal bins\n",
    "    #                         mode_forward='forward' calculating outputs using optimals bins as input \n",
    "    #\n",
    "    \n",
    "    #Need for feed forward categorial variables\n",
    "    #Take value from dictionary var_list_bins and answer if current value is in list\n",
    "    #If yes - return list\n",
    "    \n",
    "    \n",
    "    def forward_cat(self,x):\n",
    "        for i in self.var_list_bins[self.column].keys():\n",
    "            if x in self.var_list_bins[self.column][i]:\n",
    "                return str(self.var_list_bins[self.column][i]) \n",
    "    \n",
    "    def binning(self,mode_output,mode_forward,column_name):\n",
    "        variable_type = self.var_list_types[column_name]\n",
    "        if (variable_type=='numeric')&(mode_forward=='forward'):         \n",
    "            #Вспомогательная переменная, хранящая разбиения по непустым значениям\n",
    "            x_bin_t = pd.cut(self.x[column_name][self.x[column_name].notnull()],bins=self.var_list_bins[column_name])    \n",
    "            #Вспомогательная переменная, хранящая one-hot по непустым значениям\n",
    "            x_bin = pd.get_dummies(x_bin_t,prefix=self.x[column_name].name,drop_first=True)\n",
    "            #Добавляем колонку с пустыми значениями\n",
    "            x_bin[self.x[column_name].name+'_ISNULL']=0\n",
    "            x_null = pd.DataFrame(self.x[column_name][self.x[column_name].isnull()])\n",
    "            for i in x_bin.columns:\n",
    "                x_null[i]=0\n",
    "            x_null[self.x[column_name].name+'_ISNULL']=1\n",
    "            del x_null[self.x[column_name].name]\n",
    "            #Если нет NULL то колонку с dummy is null удаляем   \n",
    "            if len(self.x[column_name][self.x[column_name].isnull()])==0:\n",
    "                del x_null[self.x[column_name].name+'_ISNULL']\n",
    "                del x_bin[self.x[column_name].name+'_ISNULL']\n",
    "            #Вспомогательная переменная, которая хранит узкий и широкий вид, включая пустые значения    \n",
    "            x_pivot = pd.concat([x_bin_t,pd.DataFrame(self.x[column_name][self.x[column_name].isnull()])]).sort_index(axis=0)        \n",
    "            del x_pivot[self.x[column_name].name]\n",
    "            #Заполняем пустые значения MISSING\n",
    "            x_pivot = x_pivot.fillna('MISSING')\n",
    "            x_pivot['val'] = self.x[column_name]        \n",
    "            #Добавляем категориям индекс (создается справочник)           \n",
    "            x_dict = x_pivot.groupby(0)[\"val\"].min().fillna(0).sort_values().reset_index().rename(index=str, columns={0: \"x\"})\n",
    "            x_dict['rownum'] = x_dict['val'].rank(method='first', na_option='top')\n",
    "            x_dict['rownum'] = x_dict['rownum'].apply(self.zero_pad)\n",
    "            x_dict[column_name] = x_dict[\"rownum\"].map(str)+x_dict[\"x\"].map(str)\n",
    "            del x_dict['val']\n",
    "            del x_dict['rownum']\n",
    "            x_d =  x_dict   \n",
    "            x_pivot[\"rownum\"] = x_pivot.index.values\n",
    "            x_pivot = pd.merge(x_pivot,x_d,left_on=0,right_on=\"x\").sort_values(by='rownum').reset_index()[column_name]\n",
    "            #Джойним значения со справочником, удаляем исходные        \n",
    "            if mode_output=='one-hot': return pd.concat([x_bin,x_null]).sort_index(axis=0) #Возвращаем в виде on-hot                            \n",
    "            if mode_output=='normal': return x_pivot #Возвращаем в \"длинном и узком\" виде               \n",
    "        if (variable_type=='cat')&(mode_forward=='forward'): \n",
    "            ####################INPUT CODE HERE#####################\n",
    "            if mode_output=='normal': \n",
    "                self.column = column_name\n",
    "                return self.x[column_name].apply(self.forward_cat)\n",
    "            if mode_output=='one-hot': \n",
    "                self.column = column_name\n",
    "                return pd.get_dummies(self.x[column_name].apply(self.forward_cat), drop_first=True,prefix=self.x[column_name].name)\n",
    "        if (variable_type=='numeric')&(mode_forward=='binning'):\n",
    "            self.var_list_bins[column_name] = self.split_numeric(column_name)\n",
    "        if (variable_type=='cat')&(mode_forward=='binning'):                \n",
    "            self.var_list_bins[column_name] = self.split_categorial(column_name)\n",
    "            #x_bin = self.split_categorial(column_name)          \n",
    "            #if mode_output=='one-hot': return pd.get_dummies(x_bin,prefix=self.x[column_name].name,drop_first=True)\n",
    "            #if mode_output=='normal': return pd.DataFrame(x_bin)\n",
    "    \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/cc_universal_sample.txt', sep=';',index_col=False, decimal='.') \n",
    "x = df.copy()\n",
    "x = x[x['FLG_90_6'].notnull()]\n",
    "x = x.reset_index()\n",
    "y = x['FLG_90_6']\n",
    "x = x.drop(['FLG_90_6','FLG_90_12','FLG_90_18','APPLICATION_ID','APPLICATION_DATE'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = Scorecard(x,y,max_bins = 8, minimum_leaf=0.001, corr_threshold=0.8)\n",
    "score1.x = x\n",
    "score1.y = y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "CLIENT_GROUP\n",
      "PRODUCT_CAT\n",
      "MAILRU_HIT_FLG\n",
      "MAILRU_SCORE\n",
      "MAILRU_OLD_SCORE\n",
      "MEGAFON_OLD_SCORE\n",
      "MEGAFON_NEW_SCORE\n",
      "BKI_HIT\n",
      "BKI_SCORE_CC_NEW\n",
      "CC_LONG_TARGET_SCORE\n",
      "SCORE_EQ\n",
      "HIT_EQ\n",
      "FPS_SCORE\n",
      "SCORE_B2\n",
      "SCORE_B3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\booba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "score1.fit(x,y,iv_treshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0]\n",
       "Index: []"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score1.x_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_binned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-726509384f29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_binned\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_binned' is not defined"
     ]
    }
   ],
   "source": [
    "x_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_one_hot:  38972\n",
      "CLIENT_GROUP\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n",
      "MAILRU_SCORE\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n",
      "MAILRU_OLD_SCORE\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n",
      "MEGAFON_OLD_SCORE\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n",
      "MEGAFON_NEW_SCORE\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n",
      "BKI_HIT\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n",
      "BKI_SCORE_CC_NEW\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n",
      "CC_LONG_TARGET_SCORE\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n",
      "SCORE_EQ\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n",
      "FPS_SCORE\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n",
      "SCORE_B2\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n",
      "SCORE_B3\n",
      "x_b:  38972\n",
      "x_one_hot:  38963\n"
     ]
    }
   ],
   "source": [
    "x_one_hot = pd.DataFrame(score1.x.index.values)\n",
    "x_one_hot_old = pd.DataFrame(x_one_hot)\n",
    "print('x_one_hot: ',len(x_one_hot))\n",
    "for c in score1.x.columns:\n",
    "    x_b = pd.DataFrame(score1.binning(mode_forward='forward',mode_output='one-hot',column_name=c))\n",
    "    print(c)\n",
    "    print('x_b: ', len(x_b))\n",
    "    x_one_hot = pd.merge(x_one_hot,x_b ,left_index=True,right_index=True)\n",
    "    print('x_one_hot: ',len(x_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one_hot[0].to_csv('./data/one-hot.csv')\n",
    "x_one_hot_old[0].to_csv('./data/one-hot_old.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38942</th>\n",
       "      <td>38951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38943</th>\n",
       "      <td>38952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38944</th>\n",
       "      <td>38953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38945</th>\n",
       "      <td>38954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38946</th>\n",
       "      <td>38955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38947</th>\n",
       "      <td>38956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38948</th>\n",
       "      <td>38957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38949</th>\n",
       "      <td>38958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38950</th>\n",
       "      <td>38959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38951</th>\n",
       "      <td>38960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38952</th>\n",
       "      <td>38961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38953</th>\n",
       "      <td>38962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38954</th>\n",
       "      <td>38963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38955</th>\n",
       "      <td>38964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38956</th>\n",
       "      <td>38965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38957</th>\n",
       "      <td>38966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38958</th>\n",
       "      <td>38967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38959</th>\n",
       "      <td>38968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38960</th>\n",
       "      <td>38969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38961</th>\n",
       "      <td>38970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38962</th>\n",
       "      <td>38971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38963</th>\n",
       "      <td>38972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38964</th>\n",
       "      <td>38973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38965</th>\n",
       "      <td>38974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38966</th>\n",
       "      <td>38975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38967</th>\n",
       "      <td>38976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38968</th>\n",
       "      <td>38977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38969</th>\n",
       "      <td>38978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38970</th>\n",
       "      <td>38979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38971</th>\n",
       "      <td>38981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38972 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          3\n",
       "4          4\n",
       "5          5\n",
       "6          6\n",
       "7          7\n",
       "8          8\n",
       "9          9\n",
       "10        10\n",
       "11        11\n",
       "12        12\n",
       "13        13\n",
       "14        14\n",
       "15        15\n",
       "16        16\n",
       "17        17\n",
       "18        18\n",
       "19        19\n",
       "20        20\n",
       "21        21\n",
       "22        22\n",
       "23        23\n",
       "24        24\n",
       "25        25\n",
       "26        26\n",
       "27        27\n",
       "28        28\n",
       "29        29\n",
       "...      ...\n",
       "38942  38951\n",
       "38943  38952\n",
       "38944  38953\n",
       "38945  38954\n",
       "38946  38955\n",
       "38947  38956\n",
       "38948  38957\n",
       "38949  38958\n",
       "38950  38959\n",
       "38951  38960\n",
       "38952  38961\n",
       "38953  38962\n",
       "38954  38963\n",
       "38955  38964\n",
       "38956  38965\n",
       "38957  38966\n",
       "38958  38967\n",
       "38959  38968\n",
       "38960  38969\n",
       "38961  38970\n",
       "38962  38971\n",
       "38963  38972\n",
       "38964  38973\n",
       "38965  38974\n",
       "38966  38975\n",
       "38967  38976\n",
       "38968  38977\n",
       "38969  38978\n",
       "38970  38979\n",
       "38971  38981\n",
       "\n",
       "[38972 rows x 1 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_one_hot_old\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAILRU_HIT_FLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38951</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38952</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38953</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38954</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38955</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38956</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38957</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38958</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38959</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38960</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38961</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38962</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38963</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38964</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38965</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38966</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38967</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38968</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38969</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38970</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38971</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38972</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38973</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38974</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38975</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38976</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38977</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38978</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38979</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38981</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38972 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MAILRU_HIT_FLG\n",
       "0        ['cat_1.0']\n",
       "1        ['cat_1.0']\n",
       "2        ['cat_1.0']\n",
       "3        ['cat_1.0']\n",
       "4        ['cat_0.0']\n",
       "5        ['cat_1.0']\n",
       "6        ['cat_1.0']\n",
       "7        ['cat_1.0']\n",
       "8        ['cat_1.0']\n",
       "9        ['cat_1.0']\n",
       "10       ['cat_1.0']\n",
       "11       ['cat_0.0']\n",
       "12       ['cat_1.0']\n",
       "13       ['cat_1.0']\n",
       "14       ['cat_1.0']\n",
       "15       ['cat_0.0']\n",
       "16       ['cat_1.0']\n",
       "17       ['cat_1.0']\n",
       "18       ['cat_1.0']\n",
       "19       ['cat_1.0']\n",
       "20       ['cat_1.0']\n",
       "21       ['cat_1.0']\n",
       "22       ['cat_1.0']\n",
       "23       ['cat_1.0']\n",
       "24       ['cat_0.0']\n",
       "25       ['cat_1.0']\n",
       "26       ['cat_1.0']\n",
       "27       ['cat_1.0']\n",
       "28       ['cat_1.0']\n",
       "29       ['cat_1.0']\n",
       "...              ...\n",
       "38951    ['cat_1.0']\n",
       "38952    ['cat_1.0']\n",
       "38953    ['cat_1.0']\n",
       "38954    ['cat_1.0']\n",
       "38955    ['cat_0.0']\n",
       "38956    ['cat_0.0']\n",
       "38957    ['cat_1.0']\n",
       "38958    ['cat_1.0']\n",
       "38959    ['cat_0.0']\n",
       "38960    ['cat_1.0']\n",
       "38961    ['cat_1.0']\n",
       "38962    ['cat_1.0']\n",
       "38963    ['cat_0.0']\n",
       "38964    ['cat_1.0']\n",
       "38965    ['cat_1.0']\n",
       "38966    ['cat_1.0']\n",
       "38967    ['cat_1.0']\n",
       "38968    ['cat_0.0']\n",
       "38969    ['cat_0.0']\n",
       "38970    ['cat_1.0']\n",
       "38971    ['cat_1.0']\n",
       "38972    ['cat_1.0']\n",
       "38973    ['cat_1.0']\n",
       "38974    ['cat_1.0']\n",
       "38975    ['cat_1.0']\n",
       "38976    ['cat_1.0']\n",
       "38977    ['cat_1.0']\n",
       "38978    ['cat_1.0']\n",
       "38979    ['cat_0.0']\n",
       "38981    ['cat_1.0']\n",
       "\n",
       "[38972 rows x 1 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score1.binning(column_name = 'MAILRU_HIT_FLG', mode_forward='forward', mode_output='normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MAILRU_SCORE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3d6be68ce038>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m#df_t = df_t.rename(index=str, columns = {col:\"x\"})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m df_iv =pd.DataFrame({'count': df_t.groupby(c)['y'].count(), \n\u001b[0m\u001b[0;32m      6\u001b[0m                          \u001b[1;34m'bad_rate'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                          \u001b[1;34m'total_goods'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[0;32m   4269\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m   4270\u001b[0m                        \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4271\u001b[1;33m                        **kwargs)\n\u001b[0m\u001b[0;32m   4272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4273\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   1624\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[0;32m    390\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m                                                     mutated=self.mutated)\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, mutated)\u001b[0m\n\u001b[0;32m   2615\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2616\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2617\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2618\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2619\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'MAILRU_SCORE'"
     ]
    }
   ],
   "source": [
    "    c = 'MAILRU_SCORE'\n",
    "    df_t = pd.DataFrame(score1.binning(mode_forward='forward',mode_output='normal',column_name=c))\n",
    "    df_t[\"y\"] = y\n",
    "            #df_t = df_t.rename(index=str, columns = {col:\"x\"})\n",
    "    df_iv =pd.DataFrame({'count': df_t.groupby(c)['y'].count(), \n",
    "                             'bad_rate': df_t.groupby(c)['y'].mean(),\n",
    "                             'total_goods': df_t.groupby(c)['y'].count() - df_t.groupby(c)['y'].sum(),\n",
    "                            'total_bads': df_t.groupby(c)['y'].sum() \n",
    "                             }).reset_index()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_num</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001: MISSING</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>004: (0.224, 0.314]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>001: MISSING</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>005: (0.314, 0.403]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>004: (0.224, 0.314]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>001: MISSING</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>006: (0.403, 0.429]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>001: MISSING</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38942</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38943</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38944</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38945</th>\n",
       "      <td>005: (0.314, 0.403]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38946</th>\n",
       "      <td>001: MISSING</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38947</th>\n",
       "      <td>001: MISSING</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38948</th>\n",
       "      <td>003: (0.176, 0.224]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38949</th>\n",
       "      <td>005: (0.314, 0.403]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38950</th>\n",
       "      <td>001: MISSING</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38951</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38952</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38953</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38954</th>\n",
       "      <td>001: MISSING</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38955</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38956</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38957</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38958</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38959</th>\n",
       "      <td>001: MISSING</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38960</th>\n",
       "      <td>001: MISSING</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38961</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38962</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38963</th>\n",
       "      <td>004: (0.224, 0.314]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38964</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38965</th>\n",
       "      <td>007: (0.429, 0.533]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38966</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38967</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38968</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38969</th>\n",
       "      <td>004: (0.224, 0.314]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38970</th>\n",
       "      <td>001: MISSING</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38971</th>\n",
       "      <td>008: (0.533, 1.948]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38972 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     x_num    y\n",
       "0      008: (0.533, 1.948]  0.0\n",
       "1      008: (0.533, 1.948]  0.0\n",
       "2      008: (0.533, 1.948]  0.0\n",
       "3      008: (0.533, 1.948]  0.0\n",
       "4             001: MISSING  0.0\n",
       "5      004: (0.224, 0.314]  0.0\n",
       "6      008: (0.533, 1.948]  0.0\n",
       "7      007: (0.429, 0.533]  0.0\n",
       "8      008: (0.533, 1.948]  0.0\n",
       "9      008: (0.533, 1.948]  0.0\n",
       "10     008: (0.533, 1.948]  0.0\n",
       "11            001: MISSING  0.0\n",
       "12     005: (0.314, 0.403]  0.0\n",
       "13     004: (0.224, 0.314]  0.0\n",
       "14     007: (0.429, 0.533]  0.0\n",
       "15            001: MISSING  0.0\n",
       "16     007: (0.429, 0.533]  0.0\n",
       "17     007: (0.429, 0.533]  0.0\n",
       "18     007: (0.429, 0.533]  0.0\n",
       "19     008: (0.533, 1.948]  0.0\n",
       "20     008: (0.533, 1.948]  0.0\n",
       "21     006: (0.403, 0.429]  0.0\n",
       "22     008: (0.533, 1.948]  0.0\n",
       "23     008: (0.533, 1.948]  0.0\n",
       "24            001: MISSING  0.0\n",
       "25     008: (0.533, 1.948]  0.0\n",
       "26     008: (0.533, 1.948]  0.0\n",
       "27     007: (0.429, 0.533]  0.0\n",
       "28     008: (0.533, 1.948]  0.0\n",
       "29     007: (0.429, 0.533]  0.0\n",
       "...                    ...  ...\n",
       "38942  007: (0.429, 0.533]  0.0\n",
       "38943  008: (0.533, 1.948]  0.0\n",
       "38944  008: (0.533, 1.948]  0.0\n",
       "38945  005: (0.314, 0.403]  0.0\n",
       "38946         001: MISSING  0.0\n",
       "38947         001: MISSING  0.0\n",
       "38948  003: (0.176, 0.224]  0.0\n",
       "38949  005: (0.314, 0.403]  0.0\n",
       "38950         001: MISSING  0.0\n",
       "38951  007: (0.429, 0.533]  0.0\n",
       "38952  007: (0.429, 0.533]  0.0\n",
       "38953  007: (0.429, 0.533]  0.0\n",
       "38954         001: MISSING  0.0\n",
       "38955  008: (0.533, 1.948]  0.0\n",
       "38956  008: (0.533, 1.948]  0.0\n",
       "38957  008: (0.533, 1.948]  0.0\n",
       "38958  007: (0.429, 0.533]  0.0\n",
       "38959         001: MISSING  0.0\n",
       "38960         001: MISSING  0.0\n",
       "38961  008: (0.533, 1.948]  0.0\n",
       "38962  007: (0.429, 0.533]  0.0\n",
       "38963  004: (0.224, 0.314]  0.0\n",
       "38964  008: (0.533, 1.948]  0.0\n",
       "38965  007: (0.429, 0.533]  0.0\n",
       "38966  008: (0.533, 1.948]  0.0\n",
       "38967  008: (0.533, 1.948]  0.0\n",
       "38968  008: (0.533, 1.948]  0.0\n",
       "38969  004: (0.224, 0.314]  0.0\n",
       "38970         001: MISSING  0.0\n",
       "38971  008: (0.533, 1.948]  0.0\n",
       "\n",
       "[38972 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2392\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2393\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-d1e5537b412d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2060\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2062\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2064\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2067\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2069\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1534\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\booba\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2393\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2395\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "df_t.groupby(df_t[1].name)['y'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAILRU_HIT_FLG</th>\n",
       "      <th>bad_rate</th>\n",
       "      <th>count</th>\n",
       "      <th>total_bads</th>\n",
       "      <th>total_goods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['cat_0.0']</td>\n",
       "      <td>0.020473</td>\n",
       "      <td>10062</td>\n",
       "      <td>206.0</td>\n",
       "      <td>9856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['cat_1.0']</td>\n",
       "      <td>0.012971</td>\n",
       "      <td>28910</td>\n",
       "      <td>375.0</td>\n",
       "      <td>28535.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MAILRU_HIT_FLG  bad_rate  count  total_bads  total_goods\n",
       "0    ['cat_0.0']  0.020473  10062       206.0       9856.0\n",
       "1    ['cat_1.0']  0.012971  28910       375.0      28535.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': [0, 1, 2, 3],\n",
       " 'var2': {2: array(['D', 'C', 'B', 'A1', 'MISSING'], dtype=object),\n",
       "  3: array(['E'], dtype=object),\n",
       "  4: array(['B1'], dtype=object)}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
